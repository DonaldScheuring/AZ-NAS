{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4cc63dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 11:11:24.123008: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-25 11:11:24.168000: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-25 11:11:24.882062: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, glob, random, argparse\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import tqdm\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# XAutoDL \n",
    "from xautodl.config_utils import load_config, dict2config, configure2str\n",
    "from xautodl.datasets import get_datasets, get_nas_search_loaders\n",
    "from xautodl.procedures import (\n",
    "    prepare_seed,\n",
    "    prepare_logger,\n",
    "    save_checkpoint,\n",
    "    copy_checkpoint,\n",
    "    get_optim_scheduler,\n",
    ")\n",
    "from xautodl.utils import get_model_infos, obtain_accuracy\n",
    "from xautodl.log_utils import AverageMeter, time_string, convert_secs2time\n",
    "from xautodl.models import get_search_spaces\n",
    "\n",
    "# API\n",
    "from nats_bench import create\n",
    "\n",
    "# custom modules\n",
    "from custom.tss_model import TinyNetwork\n",
    "from xautodl.models.cell_searchs.genotypes import Structure\n",
    "from ZeroShotProxy import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6018e93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Namespace(data_path='./cifar.python', dataset='cifar10', search_space='tss', config_path='./configs/nas-benchmark/algos/weight-sharing.config', max_nodes=4, channel=16, num_cells=5, affine=1, track_running_stats=0, print_freq=200, gpu=0, workers=4, api_data_path='./api_data/NATS-tss-v1_0-3ffb9-simple/', save_dir='./results/tmp', zero_shot_score='az_nas_time', rand_seed=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\"Training-free NAS on NAS-Bench-201 (NATS-Bench-TSS)\")\n",
    "parser.add_argument(\"--data_path\", type=str, default='./cifar.python', help=\"The path to dataset\")\n",
    "parser.add_argument(\"--dataset\", type=str, default='cifar10',choices=[\"cifar10\", \"cifar100\", \"ImageNet16-120\"], help=\"Choose between Cifar10/100 and ImageNet-16.\")\n",
    "\n",
    "# channels and number-of-cells\n",
    "parser.add_argument(\"--search_space\", type=str, default='tss', help=\"The search space name.\")\n",
    "parser.add_argument(\"--config_path\", type=str, default='./configs/nas-benchmark/algos/weight-sharing.config', help=\"The path to the configuration.\")\n",
    "parser.add_argument(\"--max_nodes\", type=int, default=4, help=\"The maximum number of nodes.\")\n",
    "parser.add_argument(\"--channel\", type=int, default=16, help=\"The number of channels.\")\n",
    "parser.add_argument(\"--num_cells\", type=int, default=5, help=\"The number of cells in one stage.\")\n",
    "parser.add_argument(\"--affine\", type=int, default=1, choices=[0, 1], help=\"Whether use affine=True or False in the BN layer.\")\n",
    "parser.add_argument(\"--track_running_stats\", type=int, default=0, choices=[0, 1], help=\"Whether use track_running_stats or not in the BN layer.\")\n",
    "\n",
    "# log\n",
    "parser.add_argument(\"--print_freq\", type=int, default=200, help=\"print frequency (default: 200)\")\n",
    "\n",
    "# custom\n",
    "parser.add_argument(\"--gpu\", type=int, default=0, help=\"\")\n",
    "parser.add_argument(\"--workers\", type=int, default=4, help=\"number of data loading workers\")\n",
    "parser.add_argument(\"--api_data_path\", type=str, default=\"./api_data/NATS-tss-v1_0-3ffb9-simple/\", help=\"\")\n",
    "parser.add_argument(\"--save_dir\", type=str, default='./results/tmp', help=\"Folder to save checkpoints and log.\")\n",
    "parser.add_argument('--zero_shot_score', type=str, default='az_nas_time')\n",
    "parser.add_argument(\"--rand_seed\", type=int, default=1, help=\"manual seed (we use 1-to-5)\")\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "if args.rand_seed is None or args.rand_seed < 0:\n",
    "    args.rand_seed = random.randint(1, 100000)\n",
    "\n",
    "print(args.rand_seed)\n",
    "print(args)\n",
    "xargs=args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8a05319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function with logger : Logger(dir=results/tmp, use-tf=False, writer=None)\n",
      "Arguments : -------------------------------\n",
      "data_path        : ./cifar.python\n",
      "dataset          : cifar10\n",
      "search_space     : tss\n",
      "config_path      : ./configs/nas-benchmark/algos/weight-sharing.config\n",
      "max_nodes        : 4\n",
      "channel          : 16\n",
      "num_cells        : 5\n",
      "affine           : 1\n",
      "track_running_stats : 0\n",
      "print_freq       : 200\n",
      "gpu              : 0\n",
      "workers          : 4\n",
      "api_data_path    : ./api_data/NATS-tss-v1_0-3ffb9-simple/\n",
      "save_dir         : ./results/tmp\n",
      "zero_shot_score  : az_nas_time\n",
      "rand_seed        : 1\n",
      "Python  Version  : 3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]\n",
      "Pillow  Version  : 9.4.0\n",
      "PyTorch Version  : 2.0.1\n",
      "cuDNN   Version  : 8500\n",
      "CUDA available   : True\n",
      "CUDA GPU numbers : 1\n",
      "CUDA_VISIBLE_DEVICES : 1\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available(), \"CUDA is not available.\"\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.set_num_threads(xargs.workers)\n",
    "prepare_seed(xargs.rand_seed)\n",
    "logger = prepare_logger(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78557cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create API = NATStopology(0/15625 architectures, fast_mode=True, file=) done\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "./configs/nas-benchmark/algos/weight-sharing.config\n",
      "Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=100, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, test_batch_size=512, class_num=10, xshape=(1, 3, 32, 32))\n",
      "||||||| cifar10    ||||||| Search-Loader-Num=391, Valid-Loader-Num=49, batch size=64\n",
      "||||||| cifar10    ||||||| Config=Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=100, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, test_batch_size=512, class_num=10, xshape=(1, 3, 32, 32))\n",
      "search space : ['none', 'skip_connect', 'nor_conv_1x1', 'nor_conv_3x3', 'avg_pool_3x3']\n"
     ]
    }
   ],
   "source": [
    "## API\n",
    "api = create(xargs.api_data_path, xargs.search_space, fast_mode=True, verbose=False)\n",
    "logger.log(\"Create API = {:} done\".format(api))\n",
    "\n",
    "## data\n",
    "train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n",
    "config = load_config(xargs.config_path, {\"class_num\": class_num, \"xshape\": xshape}, logger)\n",
    "search_loader, train_loader, valid_loader = get_nas_search_loaders(train_data,\n",
    "                                                                   valid_data,\n",
    "                                                                   xargs.dataset,\n",
    "                                                                   \"./configs/nas-benchmark/\",\n",
    "                                                                   (config.batch_size, config.test_batch_size),\n",
    "                                                                   xargs.workers,)\n",
    "logger.log(\"||||||| {:10s} ||||||| Search-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\".format(xargs.dataset, len(search_loader), len(valid_loader), config.batch_size))\n",
    "logger.log(\"||||||| {:10s} ||||||| Config={:}\".format(xargs.dataset, config))\n",
    "\n",
    "## model\n",
    "search_space = get_search_spaces(xargs.search_space, \"nats-bench\")\n",
    "logger.log(\"search space : {:}\".format(search_space))\n",
    "\n",
    "device = torch.device('cuda:{}'.format(xargs.gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c557c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_genotype(max_nodes, op_names):\n",
    "    genotypes = []\n",
    "    for i in range(1, max_nodes):\n",
    "        xlist = []\n",
    "        for j in range(i):\n",
    "            node_str = \"{:}<-{:}\".format(i, j)\n",
    "            op_name = random.choice(op_names)\n",
    "            xlist.append((op_name, j))\n",
    "        genotypes.append(tuple(xlist))\n",
    "    arch = Structure(genotypes)\n",
    "    return arch\n",
    "\n",
    "real_input_metrics = ['zico', 'snip', 'grasp', 'te_nas', 'gradsign']\n",
    "    \n",
    "def search_find_best(xargs, xloader, n_samples = None, archs = None):\n",
    "    logger.log(\"Searching with {}\".format(xargs.zero_shot_score.lower()))\n",
    "    score_fn_name = \"compute_{}_score\".format(xargs.zero_shot_score.lower())\n",
    "    score_fn = globals().get(score_fn_name)\n",
    "    input_, target_ = next(iter(xloader))\n",
    "    resolution = input_.size(2)\n",
    "    batch_size = input_.size(0)\n",
    "    zero_shot_score_dict = None\n",
    "    arch_list = []\n",
    "    if xargs.zero_shot_score.lower() in real_input_metrics:\n",
    "        print('Use real images as inputs')\n",
    "        trainloader = train_loader\n",
    "    else:\n",
    "        print('Use random inputs')\n",
    "        trainloader = None\n",
    "        \n",
    "    if archs is None and n_samples is not None:\n",
    "        all_time = []\n",
    "        all_mem = []\n",
    "        fwrd_time = []\n",
    "        exp_time = []\n",
    "        bkwd_time = []\n",
    "        trn_time = []\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        for i in tqdm.tqdm(range(n_samples)):\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            # random sampling\n",
    "            arch = random_genotype(xargs.max_nodes, search_space)\n",
    "            network = TinyNetwork(xargs.channel, xargs.num_cells, arch, class_num)\n",
    "            network = network.to(device)\n",
    "            network.train()\n",
    "\n",
    "            start.record()\n",
    "            \n",
    "\n",
    "            info_dict = score_fn.compute_nas_score(network, gpu=xargs.gpu, trainloader=trainloader, resolution=resolution, batch_size=batch_size)\n",
    "\n",
    "            end.record()\n",
    "            torch.cuda.synchronize()\n",
    "            all_time.append(start.elapsed_time(end))\n",
    "#             all_mem.append(torch.cuda.max_memory_reserved())\n",
    "            all_mem.append(torch.cuda.max_memory_allocated())\n",
    "    \n",
    "            fwrd_time.append(info_dict['fwrd_time'])\n",
    "            bkwd_time.append(info_dict['bkwd_time'])\n",
    "            exp_time.append(info_dict['exp_time'])\n",
    "            trn_time.append(info_dict['trn_time'])\n",
    "\n",
    "            arch_list.append(arch)\n",
    "            if zero_shot_score_dict is None: # initialize dict\n",
    "                zero_shot_score_dict = dict()\n",
    "                for k in info_dict.keys():\n",
    "                    zero_shot_score_dict[k] = []\n",
    "            for k, v in info_dict.items():\n",
    "                zero_shot_score_dict[k].append(v)\n",
    "\n",
    "        logger.log(\"------Runtime------\")\n",
    "        logger.log(\"All: {:.5f} ms\".format(np.mean(all_time)))\n",
    "        logger.log(\"------Runtime - forward------\")\n",
    "        logger.log(\"All: {:.5f} ms\".format(np.mean(fwrd_time)))\n",
    "        logger.log(\"------Runtime - backwrad------\")\n",
    "        logger.log(\"All: {:.5f} ms\".format(np.mean(bkwd_time)))\n",
    "        logger.log(\"------Runtime - exp/prog------\")\n",
    "        logger.log(\"All: {:.5f} ms\".format(np.mean(exp_time)))\n",
    "        logger.log(\"------Runtime - trn------\")\n",
    "        logger.log(\"All: {:.5f} ms\".format(np.mean(trn_time)))\n",
    "        logger.log(\"------Avg Mem------\")\n",
    "        logger.log(\"All: {:.5f} GB\".format(np.mean(all_mem)/1e9))\n",
    "        logger.log(\"------Max Mem------\")\n",
    "        logger.log(\"All: {:.5f} GB\".format(np.max(all_mem)/1e9))\n",
    "        \n",
    "    elif archs is not None and n_samples is None:\n",
    "        all_time = []\n",
    "        all_mem = []\n",
    "        fwrd_time = []\n",
    "        exp_time = []\n",
    "        bkwd_time = []\n",
    "        trn_time = []\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        for arch in tqdm.tqdm(archs):\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            network = TinyNetwork(xargs.channel, xargs.num_cells, arch, class_num)\n",
    "            network = network.to(device)\n",
    "            network.train()\n",
    "\n",
    "            start.record()\n",
    "            \n",
    "\n",
    "            info_dict = score_fn.compute_nas_score(network, gpu=xargs.gpu, trainloader=trainloader, resolution=resolution, batch_size=batch_size)\n",
    "\n",
    "            end.record()\n",
    "            torch.cuda.synchronize()\n",
    "            all_time.append(start.elapsed_time(end))\n",
    "#             all_mem.append(torch.cuda.max_memory_reserved())\n",
    "            all_mem.append(torch.cuda.max_memory_allocated())\n",
    "    \n",
    "            fwrd_time.append(info_dict['fwrd_time'])\n",
    "            bkwd_time.append(info_dict['bkwd_time'])\n",
    "            exp_time.append(info_dict['exp_time'])\n",
    "            trn_time.append(info_dict['trn_time'])\n",
    "\n",
    "            arch_list.append(arch)\n",
    "            if zero_shot_score_dict is None: # initialize dict\n",
    "                zero_shot_score_dict = dict()\n",
    "                for k in info_dict.keys():\n",
    "                    zero_shot_score_dict[k] = []\n",
    "            for k, v in info_dict.items():\n",
    "                zero_shot_score_dict[k].append(v)\n",
    "\n",
    "        logger.log(\"------Runtime------\")\n",
    "        logger.log(\"All: {:.5f} ms\".format(np.mean(all_time)))\n",
    "        logger.log(\"------Runtime - forward------\")\n",
    "        logger.log(\"All: {:.5f} ms\".format(np.mean(fwrd_time)))\n",
    "        logger.log(\"------Runtime - backwrad------\")\n",
    "        logger.log(\"All: {:.5f} ms\".format(np.mean(bkwd_time)))\n",
    "        logger.log(\"------Runtime - exp/prog------\")\n",
    "        logger.log(\"All: {:.5f} ms\".format(np.mean(exp_time)))\n",
    "        logger.log(\"------Runtime - trn------\")\n",
    "        logger.log(\"All: {:.5f} ms\".format(np.mean(trn_time)))\n",
    "        logger.log(\"------Avg Mem------\")\n",
    "        logger.log(\"All: {:.5f} GB\".format(np.mean(all_mem)/1e9))\n",
    "        logger.log(\"------Max Mem------\")\n",
    "        logger.log(\"All: {:.5f} GB\".format(np.max(all_mem)/1e9))\n",
    "        \n",
    "    return arch_list, zero_shot_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2967c488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562c71e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching with az_nas_time\n",
      "Use random inputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15625/15625 [18:45<00:00, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Runtime------\n",
      "All: 45.56091 ms\n",
      "------Runtime - forward------\n",
      "All: 7.49732 ms\n",
      "------Runtime - backwrad------\n",
      "All: 9.61485 ms\n",
      "------Runtime - exp/prog------\n",
      "All: 10.51265 ms\n",
      "------Runtime - trn------\n",
      "All: 13.63413 ms\n",
      "------Avg Mem------\n",
      "All: 0.28326 GB\n",
      "------Max Mem------\n",
      "All: 0.53120 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ######### search across random N archs #########\n",
    "# archs, results = search_find_best(xargs, train_loader, n_samples=100)\n",
    "\n",
    "# ######### search across N archs uniformly sampled according to test acc. #########\n",
    "# def uniform_sample_archs(search_space, xargs, api, n_samples=1000, dataset='ImageNet16-120'):\n",
    "#     arch = random_genotype(xargs.max_nodes, search_space)\n",
    "#     search_space = get_search_spaces(xargs.search_space, \"nats-bench\")\n",
    "#     archs = arch.gen_all(search_space, xargs.max_nodes, False)\n",
    "    \n",
    "#     def get_results_from_api(api, arch, dataset='cifar10'):\n",
    "#         dataset_candidates = ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120']\n",
    "#         assert dataset in dataset_candidates\n",
    "#         index = api.query_index_by_arch(arch)\n",
    "#         api._prepare_info(index)\n",
    "#         archresult = api.arch2infos_dict[index]['200']\n",
    "#         if dataset == 'cifar10-valid':\n",
    "#             acc = archresult.get_metrics(dataset, 'x-valid', iepoch=None, is_random=False)['accuracy']\n",
    "#         elif dataset == 'cifar10':\n",
    "#             acc = archresult.get_metrics(dataset, 'ori-test', iepoch=None, is_random=False)['accuracy']\n",
    "#         else:\n",
    "#             acc = archresult.get_metrics(dataset, 'x-test', iepoch=None, is_random=False)['accuracy']\n",
    "#         return acc\n",
    "\n",
    "#     accs = []\n",
    "#     for a in archs:\n",
    "#         accs.append(get_results_from_api(api, a, dataset))\n",
    "#     interval = len(archs) // n_samples\n",
    "#     sorted_indices = np.argsort(accs)\n",
    "#     new_archs = []\n",
    "#     for i, idx in enumerate(sorted_indices):\n",
    "#         if i % interval == 0:\n",
    "#             new_archs.append(archs[idx])\n",
    "#     archs = new_archs\n",
    "    \n",
    "#     return archs\n",
    "\n",
    "# if os.path.exists(\"./tss_uniform_arch.pickle\"):\n",
    "#     with open(\"./tss_uniform_arch.pickle\", \"rb\") as fp:\n",
    "#         uniform_archs = pickle.load(fp)\n",
    "# else:\n",
    "#     uniform_archs = uniform_sample_archs(search_space, xargs, api, 1000, 'ImageNet16-120')\n",
    "#     with open(\"./tss_uniform_arch.pickle\", \"wb\") as fp:\n",
    "#         pickle.dump(uniform_archs, fp)\n",
    "        \n",
    "# result_path = \"./{}_uniform_arch.pickle\".format(args.zero_shot_score)\n",
    "# if os.path.exists(result_path):\n",
    "#     print(\"results already exists\")\n",
    "#     with open(result_path, \"rb\") as fp:\n",
    "#         results = pickle.load(fp)\n",
    "#     archs = uniform_archs\n",
    "# else:\n",
    "#     archs, results = search_find_best(xargs, train_loader, archs=uniform_archs)\n",
    "#     with open(result_path, \"wb\") as fp:\n",
    "#         pickle.dump(results, fp)\n",
    "\n",
    "\n",
    "######### search across all archs #########\n",
    "def generate_all_archs(search_space, xargs):\n",
    "    arch = random_genotype(xargs.max_nodes, search_space)\n",
    "    archs = arch.gen_all(search_space, xargs.max_nodes, False)\n",
    "    return archs\n",
    "\n",
    "if os.path.exists(\"./tss_all_arch.pickle\"):\n",
    "    with open(\"./tss_all_arch.pickle\", \"rb\") as fp:\n",
    "        all_archs = pickle.load(fp)\n",
    "else:\n",
    "    all_archs = generate_all_archs(search_space, xargs)\n",
    "    with open(\"./tss_all_arch.pickle\", \"wb\") as fp:\n",
    "        pickle.dump(all_archs, fp)\n",
    "\n",
    "archs, results = search_find_best(xargs, train_loader, archs=all_archs)\n",
    "\n",
    "# ####\n",
    "# result_path = \"./{}_all_arch.pickle\".format(args.zero_shot_score)\n",
    "# if os.path.exists(result_path):\n",
    "#     print(\"results already exists\")\n",
    "#     with open(result_path, \"rb\") as fp:\n",
    "#         results = pickle.load(fp)\n",
    "#     archs = all_archs\n",
    "# else:\n",
    "#     archs, results = search_find_best(xargs, train_loader, archs=all_archs)\n",
    "#     with open(result_path, \"wb\") as fp:\n",
    "#         pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67623abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
