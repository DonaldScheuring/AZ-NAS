{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902bb49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 07:54:53.443072: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, glob, random, argparse\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# XAutoDL \n",
    "from xautodl.config_utils import load_config, dict2config, configure2str\n",
    "from xautodl.datasets import get_datasets, get_nas_search_loaders\n",
    "from xautodl.procedures import (\n",
    "    prepare_seed,\n",
    "    prepare_logger,\n",
    "    save_checkpoint,\n",
    "    copy_checkpoint,\n",
    "    get_optim_scheduler,\n",
    ")\n",
    "from xautodl.utils import get_model_infos, obtain_accuracy\n",
    "from xautodl.log_utils import AverageMeter, time_string, convert_secs2time\n",
    "from xautodl.models import get_search_spaces\n",
    "\n",
    "from custom_models import get_cell_based_tiny_net\n",
    "from custom_search_cells import NAS201SearchCell as SearchCell\n",
    "from xautodl.models.cell_searchs.genotypes import Structure\n",
    "\n",
    "# NB201\n",
    "from nas_201_api import NASBench201API as API\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "792763c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54447\n",
      "Namespace(arch_nas_dataset=None, channel=16, config_path='./MY.config', data_path='../cifar.python', dataset='cifar10', max_nodes=4, num_cells=5, print_freq=200, rand_seed=54447, save_dir='./op_level-arch_loop-reset_cell_params-loop5_ep1', search_space_name='nas-bench-201', select_num=100, track_running_stats=0, workers=4)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\"Random search for NAS.\")\n",
    "parser.add_argument(\"--data_path\", type=str, default='../cifar.python', help=\"The path to dataset\")\n",
    "parser.add_argument(\"--dataset\", type=str, default='cifar10',choices=[\"cifar10\", \"cifar100\", \"ImageNet16-120\"], help=\"Choose between Cifar10/100 and ImageNet-16.\")\n",
    "\n",
    "# channels and number-of-cells\n",
    "parser.add_argument(\"--search_space_name\", type=str, default='nas-bench-201', help=\"The search space name.\")\n",
    "parser.add_argument(\"--config_path\", type=str, default='./MY.config', help=\"The path to the configuration.\")\n",
    "parser.add_argument(\"--max_nodes\", type=int, default=4, help=\"The maximum number of nodes.\")\n",
    "parser.add_argument(\"--channel\", type=int, default=16, help=\"The number of channels.\")\n",
    "parser.add_argument(\"--num_cells\", type=int, default=5, help=\"The number of cells in one stage.\")\n",
    "parser.add_argument(\"--select_num\", type=int, default=100, help=\"The number of selected architectures to evaluate.\")\n",
    "parser.add_argument(\"--track_running_stats\", type=int, default=0, choices=[0, 1], help=\"Whether use track_running_stats or not in the BN layer.\")\n",
    "# log\n",
    "parser.add_argument(\"--workers\", type=int, default=4, help=\"number of data loading workers\")\n",
    "parser.add_argument(\"--save_dir\", type=str, default='./op_level-arch_loop-reset_cell_params-loop5_ep1', help=\"Folder to save checkpoints and log.\")\n",
    "# parser.add_argument(\"--arch_nas_dataset\", type=str, default='../NAS-Bench-201-v1_1-096897.pth', help=\"The path to load the architecture dataset (tiny-nas-benchmark).\")\n",
    "parser.add_argument(\"--arch_nas_dataset\", type=str, default=None, help=\"The path to load the architecture dataset (tiny-nas-benchmark).\")\n",
    "parser.add_argument(\"--print_freq\", type=int, default=200, help=\"print frequency (default: 200)\")\n",
    "parser.add_argument(\"--rand_seed\", type=int, default=None, help=\"manual seed\")\n",
    "args = parser.parse_args(args=[])\n",
    "if args.rand_seed is None or args.rand_seed < 0:\n",
    "    args.rand_seed = random.randint(1, 100000)\n",
    "\n",
    "    \n",
    "print(args.rand_seed)\n",
    "print(args)\n",
    "xargs=args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dcd1b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function with logger : Logger(dir=op_level-arch_loop-reset_cell_params-loop5_ep1, use-tf=False, writer=None)\n",
      "Arguments : -------------------------------\n",
      "arch_nas_dataset : None\n",
      "channel          : 16\n",
      "config_path      : ./MY.config\n",
      "data_path        : ../cifar.python\n",
      "dataset          : cifar10\n",
      "max_nodes        : 4\n",
      "num_cells        : 5\n",
      "print_freq       : 200\n",
      "rand_seed        : 54447\n",
      "save_dir         : ./op_level-arch_loop-reset_cell_params-loop5_ep1\n",
      "search_space_name : nas-bench-201\n",
      "select_num       : 100\n",
      "track_running_stats : 0\n",
      "workers          : 4\n",
      "Python  Version  : 3.7.13 (default, Mar 29 2022, 02:18:16)  [GCC 7.5.0]\n",
      "Pillow  Version  : 9.0.1\n",
      "PyTorch Version  : 1.12.0\n",
      "cuDNN   Version  : 8302\n",
      "CUDA available   : True\n",
      "CUDA GPU numbers : 2\n",
      "CUDA_VISIBLE_DEVICES : None\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available(), \"CUDA is not available.\"\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.set_num_threads(xargs.workers)\n",
    "prepare_seed(xargs.rand_seed)\n",
    "logger = prepare_logger(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9daa5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "./MY.config\n",
      "Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=50, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, test_batch_size=512, class_num=10, xshape=(1, 3, 32, 32))\n",
      "||||||| cifar10    ||||||| Search-Loader-Num=391, Valid-Loader-Num=49, batch size=64\n",
      "||||||| cifar10    ||||||| Config=Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=50, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, test_batch_size=512, class_num=10, xshape=(1, 3, 32, 32))\n",
      "w-optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.025\n",
      "    lr: 0.025\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "w-scheduler : CosineAnnealingLR(warmup=0, max-epoch=50, current::epoch=0, iter=0.00, type=cosine, T-max=50, eta-min=0.001)\n",
      "criterion   : CrossEntropyLoss()\n",
      "[2022-11-02 07:54:56] create API = None done\n",
      "=> do not find the last-info file : op_level-arch_loop-reset_cell_params-loop5_ep1/seed-54447-last-info.pth\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n",
    "config = load_config(xargs.config_path, {\"class_num\": class_num, \"xshape\": xshape}, logger)\n",
    "search_loader, _, valid_loader = get_nas_search_loaders(train_data,\n",
    "                                                        valid_data,\n",
    "                                                        xargs.dataset,\n",
    "                                                        \"../configs/nas-benchmark/\",\n",
    "                                                        (config.batch_size, config.test_batch_size),\n",
    "                                                        xargs.workers)\n",
    "logger.log(\"||||||| {:10s} ||||||| Search-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\".format(\n",
    "            xargs.dataset, len(search_loader), len(valid_loader), config.batch_size))\n",
    "logger.log(\"||||||| {:10s} ||||||| Config={:}\".format(xargs.dataset, config))\n",
    "\n",
    "search_space = get_search_spaces(\"cell\", xargs.search_space_name)\n",
    "model_config = dict2config(\n",
    "    {\n",
    "        \"name\": \"RANDOM\",\n",
    "        \"C\": xargs.channel,\n",
    "        \"N\": xargs.num_cells,\n",
    "        \"max_nodes\": xargs.max_nodes,\n",
    "        \"num_classes\": class_num,\n",
    "        \"space\": search_space,\n",
    "        \"affine\": False,\n",
    "        \"track_running_stats\": bool(xargs.track_running_stats),\n",
    "    },\n",
    "    None,\n",
    ")\n",
    "search_model = get_cell_based_tiny_net(model_config)\n",
    "\n",
    "w_optimizer, w_scheduler, criterion = get_optim_scheduler(search_model.parameters(), config)\n",
    "\n",
    "logger.log(\"w-optimizer : {:}\".format(w_optimizer))\n",
    "logger.log(\"w-scheduler : {:}\".format(w_scheduler))\n",
    "logger.log(\"criterion   : {:}\".format(criterion))\n",
    "# if xargs.arch_nas_dataset is None:\n",
    "api = None\n",
    "# else:\n",
    "#     api = API(xargs.arch_nas_dataset)\n",
    "logger.log(\"{:} create API = {:} done\".format(time_string(), api))\n",
    "\n",
    "last_info, model_base_path, model_best_path = (\n",
    "    logger.path(\"info\"),\n",
    "    logger.path(\"model\"),\n",
    "    logger.path(\"best\"),\n",
    ")\n",
    "network, criterion = torch.nn.DataParallel(search_model).cuda(), criterion.cuda()\n",
    "\n",
    "if last_info.exists():  # automatically resume from previous checkpoint\n",
    "    logger.log(\n",
    "        \"=> loading checkpoint of the last-info '{:}' start\".format(last_info)\n",
    "    )\n",
    "    last_info = torch.load(last_info)\n",
    "    start_epoch = last_info[\"epoch\"]\n",
    "    checkpoint = torch.load(last_info[\"last_checkpoint\"])\n",
    "    genotypes = checkpoint[\"genotypes\"]\n",
    "    valid_accuracies = checkpoint[\"valid_accuracies\"]\n",
    "    search_model.load_state_dict(checkpoint[\"search_model\"])\n",
    "    w_scheduler.load_state_dict(checkpoint[\"w_scheduler\"])\n",
    "    w_optimizer.load_state_dict(checkpoint[\"w_optimizer\"])\n",
    "    logger.log(\n",
    "        \"=> loading checkpoint of the last-info '{:}' start with {:}-th epoch.\".format(\n",
    "            last_info, start_epoch\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    logger.log(\"=> do not find the last-info file : {:}\".format(last_info))\n",
    "    start_epoch, valid_accuracies, genotypes = 0, {\"best\": -1}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ba0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_confidence_robustness_metrics(network, inputs, targets):\n",
    "    with torch.no_grad():\n",
    "        # accuracy\n",
    "        network.train()\n",
    "        _, logits = network(inputs)\n",
    "        val_top1, val_top5 = obtain_accuracy(logits.data, targets.data, topk=(1, 5))\n",
    "        acc = val_top1\n",
    "        \n",
    "        # confidence\n",
    "        prob = torch.nn.functional.softmax(logits, dim=1)\n",
    "        one_hot_idx = torch.nn.functional.one_hot(targets)\n",
    "        confidence = (prob[one_hot_idx==1].sum()) / inputs.size(0) * 100 # in percent\n",
    "        \n",
    "        # sensitivity\n",
    "        _, noisy_logits = network(inputs + torch.randn_like(inputs)*0.1)\n",
    "        kl_loss = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        sensitivity = kl_loss(torch.nn.functional.log_softmax(noisy_logits, dim=1), torch.nn.functional.softmax(logits, dim=1))\n",
    "        \n",
    "        # robustness\n",
    "        original_weights = deepcopy(network.state_dict())\n",
    "        for m in network.modules():\n",
    "            if isinstance(m, SearchCell):\n",
    "                for p in m.parameters():\n",
    "                    p.add_(torch.randn_like(p) * p.std()*0.3)\n",
    "            \n",
    "        _, noisy_logits = network(inputs)\n",
    "        kl_loss = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        robustness = -kl_loss(torch.nn.functional.log_softmax(noisy_logits, dim=1), torch.nn.functional.softmax(logits, dim=1))\n",
    "        network.load_state_dict(original_weights)\n",
    "                \n",
    "        return acc.item(), confidence.item(), sensitivity.item(), robustness.item()\n",
    "    \n",
    "def step_sim_metric(network, criterion, inputs, targets):\n",
    "    original_dict = deepcopy(network.state_dict())\n",
    "    optim_large_step = torch.optim.SGD(network.parameters(), lr=0.025)\n",
    "    \n",
    "    # single large step\n",
    "    network.train()\n",
    "    optim_large_step.zero_grad()\n",
    "    _, logits = network(inputs)\n",
    "    base_loss = criterion(logits, targets)\n",
    "    base_loss.backward()\n",
    "    optim_large_step.step()\n",
    "    large_step_dict = deepcopy(network.state_dict())\n",
    "    \n",
    "    # multiple small steps\n",
    "    network.load_state_dict(original_dict)\n",
    "    optim_small_step = torch.optim.SGD(network.parameters(), lr=0.025/3)\n",
    "    for i in range(3):\n",
    "        optim_small_step.zero_grad()\n",
    "        _, logits = network(inputs)\n",
    "        base_loss = criterion(logits, targets)\n",
    "        base_loss.backward()\n",
    "        optim_small_step.step()\n",
    "    small_step_dict = deepcopy(network.state_dict())\n",
    "    scores = []\n",
    "    for key in large_step_dict.keys():\n",
    "        if ('weight' in key) and (original_dict[key].dim()==4):\n",
    "            if (original_dict[key] != large_step_dict[key]).sum():\n",
    "                large_step = large_step_dict[key] - original_dict[key]\n",
    "                small_step = small_step_dict[key] - original_dict[key]\n",
    "                co, ci, kh, kw = large_step.size()\n",
    "                large_step = large_step.view(co, -1)\n",
    "                small_step = small_step.view(co, -1)\n",
    "                score = torch.nn.functional.cosine_similarity(large_step, small_step, dim=1)\n",
    "                score = score.mean().item() * 100 # in percent\n",
    "                scores.append(score)\n",
    "    if len(scores)==0:\n",
    "        step_sim = 100\n",
    "        raise RuntimeError\n",
    "    else:\n",
    "        step_sim = np.mean(scores)\n",
    "    \n",
    "    # resume\n",
    "    network.load_state_dict(original_dict)\n",
    "            \n",
    "    return step_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cdab22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of nodes:60\n",
      "target_node:1 4\n",
      "target_node:2 24\n",
      "target_node:3 124\n",
      "\n",
      "\n",
      " Searching with a cell #0\n",
      "\n",
      "Current target cell:0 / current target node:1\n",
      "*Train* [2022-11-02 07:55:00] Ep:0 [000/391] Time 2.82 (2.82) Data 0.19 (0.19) Base [Loss 2.356 (2.356)  Prec@1 7.81 (7.81) Prec@5 48.44 (48.44)]\n",
      "*Train* [2022-11-02 07:55:20] Ep:0 [200/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 1.605 (1.921)  Prec@1 43.75 (27.55) Prec@5 92.19 (81.28)]\n",
      "*Train* [2022-11-02 07:55:34] Ep:0 [390/391] Time 0.06 (0.09) Data 0.00 (0.00) Base [Loss 1.649 (1.816)  Prec@1 32.50 (31.85) Prec@5 87.50 (84.23)]\n",
      "Ep:0 ends : loss=1.82, accuracy@1=31.85%, accuracy@5=84.23%\n",
      "*Train* [2022-11-02 07:55:35] Ep:1 [000/391] Time 0.31 (0.31) Data 0.23 (0.23) Base [Loss 1.490 (1.490)  Prec@1 34.38 (34.38) Prec@5 90.62 (90.62)]\n",
      "*Train* [2022-11-02 07:55:58] Ep:1 [200/391] Time 0.11 (0.12) Data 0.00 (0.00) Base [Loss 1.814 (1.562)  Prec@1 32.81 (42.45) Prec@5 84.38 (90.80)]\n",
      "*Train* [2022-11-02 07:56:22] Ep:1 [390/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 1.712 (1.523)  Prec@1 42.50 (44.06) Prec@5 95.00 (91.42)]\n",
      "Ep:1 ends : loss=1.52, accuracy@1=44.06%, accuracy@5=91.42%\n",
      "Found best op for target cell:0 / target node:1\n",
      ": Structure(4 nodes with |nor_conv_1x1~0|+|none~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=46.48%, confidence=34.086%, sensitivity=0.002, robustness=-0.014, step_sim=99.923\n",
      "\n",
      "Current target cell:0 / current target node:2\n",
      "*Train* [2022-11-02 07:56:26] Ep:0 [000/391] Time 0.34 (0.34) Data 0.25 (0.25) Base [Loss 2.504 (2.504)  Prec@1 18.75 (18.75) Prec@5 67.19 (67.19)]\n",
      "*Train* [2022-11-02 07:56:42] Ep:0 [200/391] Time 0.12 (0.08) Data 0.00 (0.00) Base [Loss 1.364 (1.503)  Prec@1 40.62 (45.20) Prec@5 93.75 (91.40)]\n",
      "*Train* [2022-11-02 07:56:58] Ep:0 [390/391] Time 0.11 (0.08) Data 0.00 (0.00) Base [Loss 1.145 (1.425)  Prec@1 57.50 (48.20) Prec@5 100.00 (92.60)]\n",
      "Ep:0 ends : loss=1.42, accuracy@1=48.20%, accuracy@5=92.60%\n",
      "*Train* [2022-11-02 07:56:59] Ep:1 [000/391] Time 0.31 (0.31) Data 0.24 (0.24) Base [Loss 1.313 (1.313)  Prec@1 54.69 (54.69) Prec@5 92.19 (92.19)]\n",
      "*Train* [2022-11-02 07:57:13] Ep:1 [200/391] Time 0.13 (0.07) Data 0.00 (0.00) Base [Loss 1.329 (1.280)  Prec@1 54.69 (53.89) Prec@5 93.75 (94.53)]\n",
      "*Train* [2022-11-02 07:57:27] Ep:1 [390/391] Time 0.06 (0.07) Data 0.00 (0.00) Base [Loss 1.351 (1.248)  Prec@1 57.50 (55.29) Prec@5 95.00 (94.84)]\n",
      "Ep:1 ends : loss=1.25, accuracy@1=55.29%, accuracy@5=94.84%\n",
      "Found best op for target cell:0 / target node:2\n",
      ": Structure(4 nodes with |nor_conv_1x1~0|+|skip_connect~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=60.55%, confidence=45.357%, sensitivity=0.008, robustness=-0.004, step_sim=99.975\n",
      "\n",
      "Current target cell:0 / current target node:3\n",
      "*Train* [2022-11-02 07:57:53] Ep:0 [000/391] Time 0.42 (0.42) Data 0.29 (0.29) Base [Loss 1.319 (1.319)  Prec@1 54.69 (54.69) Prec@5 90.62 (90.62)]\n",
      "*Train* [2022-11-02 07:58:19] Ep:0 [200/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 1.127 (1.275)  Prec@1 60.94 (54.66) Prec@5 96.88 (94.31)]\n",
      "*Train* [2022-11-02 07:58:42] Ep:0 [390/391] Time 0.07 (0.13) Data 0.00 (0.00) Base [Loss 1.360 (1.209)  Prec@1 40.00 (57.01) Prec@5 92.50 (95.03)]\n",
      "Ep:0 ends : loss=1.21, accuracy@1=57.01%, accuracy@5=95.03%\n",
      "*Train* [2022-11-02 07:58:42] Ep:1 [000/391] Time 0.39 (0.39) Data 0.24 (0.24) Base [Loss 1.332 (1.332)  Prec@1 54.69 (54.69) Prec@5 93.75 (93.75)]\n",
      "*Train* [2022-11-02 07:59:03] Ep:1 [200/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 1.050 (1.125)  Prec@1 67.19 (59.53) Prec@5 96.88 (95.83)]\n",
      "*Train* [2022-11-02 07:59:19] Ep:1 [390/391] Time 0.07 (0.09) Data 0.00 (0.00) Base [Loss 0.961 (1.103)  Prec@1 67.50 (60.44) Prec@5 97.50 (96.05)]\n",
      "Ep:1 ends : loss=1.10, accuracy@1=60.44%, accuracy@5=96.05%\n",
      "Found best op for target cell:0 / target node:3\n",
      ": Structure(4 nodes with |nor_conv_1x1~0|+|skip_connect~0|skip_connect~1|+|avg_pool_3x3~0|skip_connect~1|nor_conv_3x3~2|) with accuracy=65.04%, confidence=50.894%, sensitivity=0.027, robustness=-0.005, step_sim=99.957\n",
      "\n",
      "\n",
      " Searching with a cell #1\n",
      "\n",
      "Current target cell:1 / current target node:1\n",
      "*Train* [2022-11-02 08:01:08] Ep:0 [000/391] Time 0.43 (0.43) Data 0.26 (0.26) Base [Loss 0.836 (0.836)  Prec@1 75.00 (75.00) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:01:33] Ep:0 [200/391] Time 0.12 (0.13) Data 0.00 (0.00) Base [Loss 0.914 (1.115)  Prec@1 65.62 (59.99) Prec@5 96.88 (95.65)]\n",
      "*Train* [2022-11-02 08:01:53] Ep:0 [390/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.961 (1.078)  Prec@1 65.00 (61.75) Prec@5 97.50 (95.92)]\n",
      "Ep:0 ends : loss=1.08, accuracy@1=61.75%, accuracy@5=95.92%\n",
      "*Train* [2022-11-02 08:01:53] Ep:1 [000/391] Time 0.34 (0.34) Data 0.24 (0.24) Base [Loss 0.983 (0.983)  Prec@1 68.75 (68.75) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:02:13] Ep:1 [200/391] Time 0.11 (0.10) Data 0.00 (0.00) Base [Loss 0.899 (1.000)  Prec@1 68.75 (64.51) Prec@5 98.44 (96.91)]\n",
      "*Train* [2022-11-02 08:02:35] Ep:1 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 1.000 (0.993)  Prec@1 65.00 (64.66) Prec@5 97.50 (96.86)]\n",
      "Ep:1 ends : loss=0.99, accuracy@1=64.66%, accuracy@5=96.86%\n",
      "Found best op for target cell:1 / target node:1\n",
      ": Structure(4 nodes with |skip_connect~0|+|none~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=65.04%, confidence=52.223%, sensitivity=0.044, robustness=-0.009, step_sim=99.972\n",
      "\n",
      "Current target cell:1 / current target node:2\n",
      "*Train* [2022-11-02 08:02:39] Ep:0 [000/391] Time 0.44 (0.44) Data 0.27 (0.27) Base [Loss 1.107 (1.107)  Prec@1 62.50 (62.50) Prec@5 95.31 (95.31)]\n",
      "*Train* [2022-11-02 08:02:58] Ep:0 [200/391] Time 0.08 (0.10) Data 0.00 (0.00) Base [Loss 0.808 (1.051)  Prec@1 73.44 (63.22) Prec@5 98.44 (96.23)]\n",
      "*Train* [2022-11-02 08:03:18] Ep:0 [390/391] Time 0.13 (0.10) Data 0.00 (0.00) Base [Loss 0.869 (1.002)  Prec@1 75.00 (64.80) Prec@5 100.00 (96.74)]\n",
      "Ep:0 ends : loss=1.00, accuracy@1=64.80%, accuracy@5=96.74%\n",
      "*Train* [2022-11-02 08:03:18] Ep:1 [000/391] Time 0.37 (0.37) Data 0.29 (0.29) Base [Loss 0.834 (0.834)  Prec@1 67.19 (67.19) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:03:38] Ep:1 [200/391] Time 0.07 (0.10) Data 0.00 (0.00) Base [Loss 0.964 (0.929)  Prec@1 62.50 (66.73) Prec@5 95.31 (97.22)]\n",
      "*Train* [2022-11-02 08:03:54] Ep:1 [390/391] Time 0.07 (0.09) Data 0.00 (0.00) Base [Loss 1.361 (0.928)  Prec@1 65.00 (67.15) Prec@5 87.50 (97.26)]\n",
      "Ep:1 ends : loss=0.93, accuracy@1=67.15%, accuracy@5=97.26%\n",
      "Found best op for target cell:1 / target node:2\n",
      ": Structure(4 nodes with |skip_connect~0|+|skip_connect~0|none~1|+|none~0|none~1|skip_connect~2|) with accuracy=66.41%, confidence=54.608%, sensitivity=0.058, robustness=-0.012, step_sim=99.965\n",
      "\n",
      "Current target cell:1 / current target node:3\n",
      "*Train* [2022-11-02 08:04:20] Ep:0 [000/391] Time 0.48 (0.48) Data 0.26 (0.26) Base [Loss 1.056 (1.056)  Prec@1 64.06 (64.06) Prec@5 95.31 (95.31)]\n",
      "*Train* [2022-11-02 08:04:40] Ep:0 [200/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.696 (0.971)  Prec@1 73.44 (65.78) Prec@5 100.00 (96.86)]\n",
      "*Train* [2022-11-02 08:05:01] Ep:0 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.838 (0.936)  Prec@1 75.00 (67.02) Prec@5 97.50 (97.17)]\n",
      "Ep:0 ends : loss=0.94, accuracy@1=67.02%, accuracy@5=97.17%\n",
      "*Train* [2022-11-02 08:05:02] Ep:1 [000/391] Time 0.48 (0.48) Data 0.30 (0.30) Base [Loss 0.862 (0.862)  Prec@1 73.44 (73.44) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:05:24] Ep:1 [200/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.966 (0.880)  Prec@1 64.06 (69.37) Prec@5 95.31 (97.69)]\n",
      "*Train* [2022-11-02 08:05:45] Ep:1 [390/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.959 (0.874)  Prec@1 62.50 (69.50) Prec@5 95.00 (97.65)]\n",
      "Ep:1 ends : loss=0.87, accuracy@1=69.50%, accuracy@5=97.65%\n",
      "Found best op for target cell:1 / target node:3\n",
      ": Structure(4 nodes with |skip_connect~0|+|skip_connect~0|none~1|+|none~0|none~1|skip_connect~2|) with accuracy=70.51%, confidence=57.477%, sensitivity=0.063, robustness=-0.011, step_sim=99.948\n",
      "\n",
      "\n",
      " Searching with a cell #2\n",
      "\n",
      "Current target cell:2 / current target node:1\n",
      "*Train* [2022-11-02 08:07:25] Ep:0 [000/391] Time 0.42 (0.42) Data 0.28 (0.28) Base [Loss 2.346 (2.346)  Prec@1 29.69 (29.69) Prec@5 73.44 (73.44)]\n",
      "*Train* [2022-11-02 08:07:45] Ep:0 [200/391] Time 0.13 (0.10) Data 0.00 (0.00) Base [Loss 0.743 (0.931)  Prec@1 70.31 (66.95) Prec@5 100.00 (97.22)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Train* [2022-11-02 08:08:06] Ep:0 [390/391] Time 0.07 (0.10) Data 0.00 (0.00) Base [Loss 0.857 (0.895)  Prec@1 70.00 (68.75) Prec@5 100.00 (97.55)]\n",
      "Ep:0 ends : loss=0.89, accuracy@1=68.75%, accuracy@5=97.55%\n",
      "*Train* [2022-11-02 08:08:06] Ep:1 [000/391] Time 0.34 (0.34) Data 0.25 (0.25) Base [Loss 0.711 (0.711)  Prec@1 70.31 (70.31) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-02 08:08:28] Ep:1 [200/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.831 (0.845)  Prec@1 71.88 (70.44) Prec@5 96.88 (97.64)]\n",
      "*Train* [2022-11-02 08:08:49] Ep:1 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.694 (0.841)  Prec@1 77.50 (70.47) Prec@5 100.00 (97.70)]\n",
      "Ep:1 ends : loss=0.84, accuracy@1=70.47%, accuracy@5=97.70%\n",
      "Found best op for target cell:2 / target node:1\n",
      ": Structure(4 nodes with |skip_connect~0|+|none~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=71.09%, confidence=58.062%, sensitivity=0.055, robustness=-0.012, step_sim=99.954\n",
      "\n",
      "Current target cell:2 / current target node:2\n",
      "*Train* [2022-11-02 08:08:53] Ep:0 [000/391] Time 0.34 (0.34) Data 0.26 (0.26) Base [Loss 0.937 (0.937)  Prec@1 64.06 (64.06) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-02 08:09:12] Ep:0 [200/391] Time 0.08 (0.10) Data 0.00 (0.00) Base [Loss 0.912 (0.944)  Prec@1 59.38 (67.54) Prec@5 98.44 (96.83)]\n",
      "*Train* [2022-11-02 08:09:34] Ep:0 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.894 (0.896)  Prec@1 67.50 (68.94) Prec@5 97.50 (97.30)]\n",
      "Ep:0 ends : loss=0.90, accuracy@1=68.94%, accuracy@5=97.30%\n",
      "*Train* [2022-11-02 08:09:34] Ep:1 [000/391] Time 0.40 (0.40) Data 0.28 (0.28) Base [Loss 1.025 (1.025)  Prec@1 65.62 (65.62) Prec@5 93.75 (93.75)]\n",
      "*Train* [2022-11-02 08:09:56] Ep:1 [200/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 1.155 (0.840)  Prec@1 57.81 (70.85) Prec@5 95.31 (97.64)]\n",
      "*Train* [2022-11-02 08:10:18] Ep:1 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.962 (0.821)  Prec@1 65.00 (71.44) Prec@5 95.00 (97.88)]\n",
      "Ep:1 ends : loss=0.82, accuracy@1=71.44%, accuracy@5=97.88%\n",
      "Found best op for target cell:2 / target node:2\n",
      ": Structure(4 nodes with |skip_connect~0|+|skip_connect~0|none~1|+|none~0|none~1|skip_connect~2|) with accuracy=72.66%, confidence=61.774%, sensitivity=0.070, robustness=-0.015, step_sim=99.941\n",
      "\n",
      "Current target cell:2 / current target node:3\n",
      "*Train* [2022-11-02 08:10:36] Ep:0 [000/391] Time 0.46 (0.46) Data 0.29 (0.29) Base [Loss 1.266 (1.266)  Prec@1 54.69 (54.69) Prec@5 90.62 (90.62)]\n",
      "*Train* [2022-11-02 08:10:52] Ep:0 [200/391] Time 0.07 (0.08) Data 0.00 (0.00) Base [Loss 1.290 (0.876)  Prec@1 56.25 (69.60) Prec@5 95.31 (97.22)]\n",
      "*Train* [2022-11-02 08:11:13] Ep:0 [390/391] Time 0.12 (0.09) Data 0.00 (0.00) Base [Loss 0.731 (0.853)  Prec@1 67.50 (70.23) Prec@5 97.50 (97.60)]\n",
      "Ep:0 ends : loss=0.85, accuracy@1=70.23%, accuracy@5=97.60%\n",
      "*Train* [2022-11-02 08:11:13] Ep:1 [000/391] Time 0.46 (0.46) Data 0.29 (0.29) Base [Loss 0.967 (0.967)  Prec@1 62.50 (62.50) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:11:38] Ep:1 [200/391] Time 0.07 (0.13) Data 0.00 (0.00) Base [Loss 0.728 (0.807)  Prec@1 79.69 (72.36) Prec@5 95.31 (97.78)]\n",
      "*Train* [2022-11-02 08:11:56] Ep:1 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.978 (0.795)  Prec@1 67.50 (72.72) Prec@5 100.00 (98.00)]\n",
      "Ep:1 ends : loss=0.79, accuracy@1=72.72%, accuracy@5=98.00%\n",
      "Found best op for target cell:2 / target node:3\n",
      ": Structure(4 nodes with |skip_connect~0|+|skip_connect~0|none~1|+|avg_pool_3x3~0|skip_connect~1|nor_conv_1x1~2|) with accuracy=73.83%, confidence=60.269%, sensitivity=0.082, robustness=-0.014, step_sim=99.944\n",
      "\n",
      "\n",
      " Searching with a cell #3\n",
      "\n",
      "Current target cell:3 / current target node:1\n",
      "*Train* [2022-11-02 08:13:26] Ep:0 [000/391] Time 0.40 (0.40) Data 0.26 (0.26) Base [Loss 0.642 (0.642)  Prec@1 81.25 (81.25) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:13:48] Ep:0 [200/391] Time 0.20 (0.11) Data 0.00 (0.00) Base [Loss 0.715 (0.888)  Prec@1 73.44 (68.95) Prec@5 100.00 (97.37)]\n",
      "*Train* [2022-11-02 08:14:08] Ep:0 [390/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.876 (0.845)  Prec@1 72.50 (70.48) Prec@5 97.50 (97.74)]\n",
      "Ep:0 ends : loss=0.85, accuracy@1=70.48%, accuracy@5=97.74%\n",
      "*Train* [2022-11-02 08:14:09] Ep:1 [000/391] Time 0.41 (0.41) Data 0.26 (0.26) Base [Loss 0.849 (0.849)  Prec@1 70.31 (70.31) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:14:32] Ep:1 [200/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.812 (0.761)  Prec@1 70.31 (73.73) Prec@5 98.44 (98.10)]\n",
      "*Train* [2022-11-02 08:14:51] Ep:1 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.549 (0.771)  Prec@1 82.50 (73.37) Prec@5 100.00 (98.16)]\n",
      "Ep:1 ends : loss=0.77, accuracy@1=73.37%, accuracy@5=98.16%\n",
      "Found best op for target cell:3 / target node:1\n",
      ": Structure(4 nodes with |skip_connect~0|+|none~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=70.12%, confidence=59.066%, sensitivity=0.077, robustness=-0.022, step_sim=99.916\n",
      "\n",
      "Current target cell:3 / current target node:2\n",
      "*Train* [2022-11-02 08:14:55] Ep:0 [000/391] Time 0.42 (0.42) Data 0.28 (0.28) Base [Loss 1.028 (1.028)  Prec@1 67.19 (67.19) Prec@5 95.31 (95.31)]\n",
      "*Train* [2022-11-02 08:15:11] Ep:0 [200/391] Time 0.08 (0.08) Data 0.00 (0.00) Base [Loss 0.626 (0.866)  Prec@1 78.12 (70.16) Prec@5 100.00 (97.53)]\n",
      "*Train* [2022-11-02 08:15:28] Ep:0 [390/391] Time 0.20 (0.09) Data 0.00 (0.00) Base [Loss 1.008 (0.838)  Prec@1 67.50 (71.00) Prec@5 100.00 (97.81)]\n",
      "Ep:0 ends : loss=0.84, accuracy@1=71.00%, accuracy@5=97.81%\n",
      "*Train* [2022-11-02 08:15:29] Ep:1 [000/391] Time 0.38 (0.38) Data 0.27 (0.27) Base [Loss 0.842 (0.842)  Prec@1 67.19 (67.19) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-02 08:15:48] Ep:1 [200/391] Time 0.08 (0.10) Data 0.00 (0.00) Base [Loss 0.576 (0.786)  Prec@1 78.12 (72.22) Prec@5 100.00 (98.18)]\n",
      "*Train* [2022-11-02 08:16:05] Ep:1 [390/391] Time 0.13 (0.09) Data 0.00 (0.00) Base [Loss 0.608 (0.784)  Prec@1 82.50 (72.68) Prec@5 100.00 (98.17)]\n",
      "Ep:1 ends : loss=0.78, accuracy@1=72.68%, accuracy@5=98.17%\n",
      "Found best op for target cell:3 / target node:2\n",
      ": Structure(4 nodes with |skip_connect~0|+|nor_conv_3x3~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=73.24%, confidence=59.277%, sensitivity=0.075, robustness=-0.019, step_sim=99.921\n",
      "\n",
      "Current target cell:3 / current target node:3\n",
      "*Train* [2022-11-02 08:16:23] Ep:0 [000/391] Time 0.40 (0.40) Data 0.26 (0.26) Base [Loss 0.909 (0.909)  Prec@1 67.19 (67.19) Prec@5 93.75 (93.75)]\n",
      "*Train* [2022-11-02 08:16:41] Ep:0 [200/391] Time 0.21 (0.09) Data 0.00 (0.00) Base [Loss 0.736 (0.833)  Prec@1 73.44 (71.53) Prec@5 98.44 (97.78)]\n",
      "*Train* [2022-11-02 08:17:05] Ep:0 [390/391] Time 0.06 (0.11) Data 0.00 (0.00) Base [Loss 0.835 (0.817)  Prec@1 75.00 (71.91) Prec@5 100.00 (97.98)]\n",
      "Ep:0 ends : loss=0.82, accuracy@1=71.91%, accuracy@5=97.98%\n",
      "*Train* [2022-11-02 08:17:05] Ep:1 [000/391] Time 0.40 (0.40) Data 0.26 (0.26) Base [Loss 0.644 (0.644)  Prec@1 76.56 (76.56) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:17:27] Ep:1 [200/391] Time 0.15 (0.11) Data 0.00 (0.00) Base [Loss 0.493 (0.763)  Prec@1 81.25 (73.84) Prec@5 98.44 (98.11)]\n",
      "*Train* [2022-11-02 08:17:49] Ep:1 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.636 (0.767)  Prec@1 82.50 (73.48) Prec@5 100.00 (98.14)]\n",
      "Ep:1 ends : loss=0.77, accuracy@1=73.48%, accuracy@5=98.14%\n",
      "Found best op for target cell:3 / target node:3\n",
      ": Structure(4 nodes with |skip_connect~0|+|nor_conv_3x3~0|skip_connect~1|+|nor_conv_1x1~0|nor_conv_3x3~1|skip_connect~2|) with accuracy=70.31%, confidence=60.605%, sensitivity=0.077, robustness=-0.023, step_sim=99.949\n",
      "\n",
      "\n",
      " Searching with a cell #4\n",
      "\n",
      "Current target cell:4 / current target node:1\n",
      "*Train* [2022-11-02 08:19:52] Ep:0 [000/391] Time 0.36 (0.36) Data 0.27 (0.27) Base [Loss 2.503 (2.503)  Prec@1 25.00 (25.00) Prec@5 70.31 (70.31)]\n",
      "*Train* [2022-11-02 08:20:13] Ep:0 [200/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.781 (0.864)  Prec@1 71.88 (70.27) Prec@5 100.00 (97.57)]\n",
      "*Train* [2022-11-02 08:20:36] Ep:0 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.593 (0.819)  Prec@1 85.00 (71.73) Prec@5 100.00 (97.89)]\n",
      "Ep:0 ends : loss=0.82, accuracy@1=71.73%, accuracy@5=97.89%\n",
      "*Train* [2022-11-02 08:20:37] Ep:1 [000/391] Time 0.38 (0.38) Data 0.29 (0.29) Base [Loss 0.904 (0.904)  Prec@1 65.62 (65.62) Prec@5 98.44 (98.44)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Train* [2022-11-02 08:21:02] Ep:1 [200/391] Time 0.12 (0.13) Data 0.00 (0.00) Base [Loss 0.635 (0.756)  Prec@1 81.25 (73.41) Prec@5 100.00 (98.35)]\n",
      "*Train* [2022-11-02 08:21:25] Ep:1 [390/391] Time 0.12 (0.13) Data 0.00 (0.00) Base [Loss 0.812 (0.756)  Prec@1 72.50 (73.58) Prec@5 97.50 (98.36)]\n",
      "Ep:1 ends : loss=0.76, accuracy@1=73.58%, accuracy@5=98.36%\n",
      "Found best op for target cell:4 / target node:1\n",
      ": Structure(4 nodes with |nor_conv_3x3~0|+|none~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=74.02%, confidence=62.287%, sensitivity=0.082, robustness=-0.026, step_sim=99.927\n",
      "\n",
      "Current target cell:4 / current target node:2\n",
      "*Train* [2022-11-02 08:21:31] Ep:0 [000/391] Time 0.46 (0.46) Data 0.32 (0.32) Base [Loss 0.799 (0.799)  Prec@1 65.62 (65.62) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:21:55] Ep:0 [200/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.913 (0.876)  Prec@1 60.94 (69.75) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-02 08:22:17] Ep:0 [390/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 1.067 (0.816)  Prec@1 70.00 (71.85) Prec@5 92.50 (97.48)]\n",
      "Ep:0 ends : loss=0.82, accuracy@1=71.85%, accuracy@5=97.48%\n",
      "*Train* [2022-11-02 08:22:17] Ep:1 [000/391] Time 0.39 (0.39) Data 0.31 (0.31) Base [Loss 0.660 (0.660)  Prec@1 76.56 (76.56) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-02 08:22:34] Ep:1 [200/391] Time 0.12 (0.09) Data 0.00 (0.00) Base [Loss 0.592 (0.749)  Prec@1 78.12 (74.00) Prec@5 98.44 (98.41)]\n",
      "*Train* [2022-11-02 08:22:52] Ep:1 [390/391] Time 0.08 (0.09) Data 0.00 (0.00) Base [Loss 0.829 (0.739)  Prec@1 67.50 (74.39) Prec@5 95.00 (98.31)]\n",
      "Ep:1 ends : loss=0.74, accuracy@1=74.39%, accuracy@5=98.31%\n",
      "Found best op for target cell:4 / target node:2\n",
      ": Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_1x1~0|none~1|+|none~0|none~1|skip_connect~2|) with accuracy=76.56%, confidence=64.604%, sensitivity=0.084, robustness=-0.031, step_sim=99.931\n",
      "\n",
      "Current target cell:4 / current target node:3\n",
      "*Train* [2022-11-02 08:23:14] Ep:0 [000/391] Time 0.35 (0.35) Data 0.25 (0.25) Base [Loss 0.619 (0.619)  Prec@1 71.88 (71.88) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-02 08:23:36] Ep:0 [200/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.773 (0.794)  Prec@1 71.88 (72.69) Prec@5 95.31 (97.74)]\n",
      "*Train* [2022-11-02 08:24:00] Ep:0 [390/391] Time 0.14 (0.12) Data 0.00 (0.00) Base [Loss 0.713 (0.762)  Prec@1 77.50 (73.63) Prec@5 97.50 (98.08)]\n",
      "Ep:0 ends : loss=0.76, accuracy@1=73.63%, accuracy@5=98.08%\n",
      "*Train* [2022-11-02 08:24:01] Ep:1 [000/391] Time 0.37 (0.37) Data 0.28 (0.28) Base [Loss 0.770 (0.770)  Prec@1 76.56 (76.56) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-02 08:24:19] Ep:1 [200/391] Time 0.12 (0.09) Data 0.00 (0.00) Base [Loss 0.734 (0.716)  Prec@1 82.81 (75.19) Prec@5 96.88 (98.36)]\n",
      "*Train* [2022-11-02 08:24:42] Ep:1 [390/391] Time 0.11 (0.11) Data 0.00 (0.00) Base [Loss 0.597 (0.718)  Prec@1 80.00 (75.43) Prec@5 100.00 (98.36)]\n",
      "Ep:1 ends : loss=0.72, accuracy@1=75.43%, accuracy@5=98.36%\n",
      "Found best op for target cell:4 / target node:3\n",
      ": Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_1x1~0|none~1|+|skip_connect~0|none~1|none~2|) with accuracy=74.22%, confidence=63.296%, sensitivity=0.090, robustness=-0.025, step_sim=99.932\n",
      "\n",
      "\n",
      " Searching with a cell #5\n",
      "\n",
      "Current target cell:5 / current target node:1\n",
      "*Train* [2022-11-02 08:26:36] Ep:0 [000/391] Time 0.34 (0.34) Data 0.26 (0.26) Base [Loss 0.755 (0.755)  Prec@1 79.69 (79.69) Prec@5 93.75 (93.75)]\n",
      "*Train* [2022-11-02 08:26:53] Ep:0 [200/391] Time 0.07 (0.09) Data 0.00 (0.00) Base [Loss 0.888 (0.943)  Prec@1 65.62 (67.70) Prec@5 96.88 (96.83)]\n",
      "*Train* [2022-11-02 08:27:11] Ep:0 [390/391] Time 0.13 (0.09) Data 0.00 (0.00) Base [Loss 0.855 (0.852)  Prec@1 62.50 (70.64) Prec@5 100.00 (97.48)]\n",
      "Ep:0 ends : loss=0.85, accuracy@1=70.64%, accuracy@5=97.48%\n",
      "*Train* [2022-11-02 08:27:11] Ep:1 [000/391] Time 0.35 (0.35) Data 0.26 (0.26) Base [Loss 0.544 (0.544)  Prec@1 81.25 (81.25) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-02 08:27:30] Ep:1 [200/391] Time 0.08 (0.10) Data 0.00 (0.00) Base [Loss 0.918 (0.713)  Prec@1 71.88 (75.10) Prec@5 96.88 (98.53)]\n",
      "*Train* [2022-11-02 08:27:46] Ep:1 [390/391] Time 0.08 (0.09) Data 0.00 (0.00) Base [Loss 0.721 (0.713)  Prec@1 77.50 (75.20) Prec@5 97.50 (98.46)]\n",
      "Ep:1 ends : loss=0.71, accuracy@1=75.20%, accuracy@5=98.46%\n",
      "Found best op for target cell:5 / target node:1\n",
      ": Structure(4 nodes with |skip_connect~0|+|none~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=72.85%, confidence=60.611%, sensitivity=0.099, robustness=-0.027, step_sim=99.914\n",
      "\n",
      "Current target cell:5 / current target node:2\n",
      "*Train* [2022-11-02 08:27:50] Ep:0 [000/391] Time 0.40 (0.40) Data 0.25 (0.25) Base [Loss 3.444 (3.444)  Prec@1 14.06 (14.06) Prec@5 48.44 (48.44)]\n",
      "*Train* [2022-11-02 08:28:11] Ep:0 [200/391] Time 0.08 (0.10) Data 0.00 (0.00) Base [Loss 0.612 (0.927)  Prec@1 75.00 (67.92) Prec@5 98.44 (96.73)]\n",
      "*Train* [2022-11-02 08:28:33] Ep:0 [390/391] Time 0.21 (0.11) Data 0.00 (0.00) Base [Loss 0.730 (0.835)  Prec@1 80.00 (71.38) Prec@5 100.00 (97.48)]\n",
      "Ep:0 ends : loss=0.83, accuracy@1=71.38%, accuracy@5=97.48%\n",
      "*Train* [2022-11-02 08:28:34] Ep:1 [000/391] Time 0.40 (0.40) Data 0.30 (0.30) Base [Loss 0.785 (0.785)  Prec@1 73.44 (73.44) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-02 08:28:55] Ep:1 [200/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.786 (0.702)  Prec@1 76.56 (75.92) Prec@5 98.44 (98.33)]\n",
      "*Train* [2022-11-02 08:29:16] Ep:1 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.561 (0.712)  Prec@1 80.00 (75.47) Prec@5 100.00 (98.34)]\n",
      "Ep:1 ends : loss=0.71, accuracy@1=75.47%, accuracy@5=98.34%\n",
      "Found best op for target cell:5 / target node:2\n",
      ": Structure(4 nodes with |skip_connect~0|+|avg_pool_3x3~0|nor_conv_3x3~1|+|none~0|none~1|skip_connect~2|) with accuracy=73.44%, confidence=61.206%, sensitivity=0.113, robustness=-0.019, step_sim=99.951\n",
      "\n",
      "Current target cell:5 / current target node:3\n",
      "*Train* [2022-11-02 08:29:43] Ep:0 [000/391] Time 0.41 (0.41) Data 0.31 (0.31) Base [Loss 0.639 (0.639)  Prec@1 78.12 (78.12) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-02 08:30:01] Ep:0 [200/391] Time 0.12 (0.09) Data 0.00 (0.00) Base [Loss 0.781 (0.906)  Prec@1 70.31 (68.94) Prec@5 98.44 (96.78)]\n",
      "*Train* [2022-11-02 08:30:22] Ep:0 [390/391] Time 0.13 (0.10) Data 0.00 (0.00) Base [Loss 0.456 (0.827)  Prec@1 87.50 (71.54) Prec@5 100.00 (97.49)]\n",
      "Ep:0 ends : loss=0.83, accuracy@1=71.54%, accuracy@5=97.49%\n",
      "*Train* [2022-11-02 08:30:22] Ep:1 [000/391] Time 0.34 (0.34) Data 0.25 (0.25) Base [Loss 0.550 (0.550)  Prec@1 82.81 (82.81) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-02 08:30:43] Ep:1 [200/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.652 (0.713)  Prec@1 82.81 (75.42) Prec@5 95.31 (98.38)]\n",
      "*Train* [2022-11-02 08:31:07] Ep:1 [390/391] Time 0.21 (0.11) Data 0.00 (0.00) Base [Loss 0.942 (0.717)  Prec@1 70.00 (75.26) Prec@5 100.00 (98.34)]\n",
      "Ep:1 ends : loss=0.72, accuracy@1=75.26%, accuracy@5=98.34%\n",
      "Found best op for target cell:5 / target node:3\n",
      ": Structure(4 nodes with |skip_connect~0|+|avg_pool_3x3~0|nor_conv_3x3~1|+|none~0|nor_conv_3x3~1|avg_pool_3x3~2|) with accuracy=74.22%, confidence=64.294%, sensitivity=0.098, robustness=-0.026, step_sim=99.952\n",
      "\n",
      "\n",
      " Searching with a cell #6\n",
      "\n",
      "Current target cell:6 / current target node:1\n",
      "*Train* [2022-11-02 08:33:11] Ep:0 [000/391] Time 0.35 (0.35) Data 0.27 (0.27) Base [Loss 0.901 (0.901)  Prec@1 73.44 (73.44) Prec@5 95.31 (95.31)]\n",
      "*Train* [2022-11-02 08:33:36] Ep:0 [200/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.767 (0.903)  Prec@1 76.56 (69.03) Prec@5 96.88 (96.93)]\n",
      "*Train* [2022-11-02 08:33:57] Ep:0 [390/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.758 (0.822)  Prec@1 72.50 (71.53) Prec@5 97.50 (97.57)]\n",
      "Ep:0 ends : loss=0.82, accuracy@1=71.53%, accuracy@5=97.57%\n",
      "*Train* [2022-11-02 08:33:58] Ep:1 [000/391] Time 0.35 (0.35) Data 0.25 (0.25) Base [Loss 0.729 (0.729)  Prec@1 73.44 (73.44) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-02 08:34:22] Ep:1 [200/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.917 (0.703)  Prec@1 71.88 (75.79) Prec@5 96.88 (98.54)]\n",
      "*Train* [2022-11-02 08:34:47] Ep:1 [390/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.595 (0.697)  Prec@1 82.50 (75.86) Prec@5 100.00 (98.54)]\n",
      "Ep:1 ends : loss=0.70, accuracy@1=75.86%, accuracy@5=98.54%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best op for target cell:6 / target node:1\n",
      ": Structure(4 nodes with |avg_pool_3x3~0|+|none~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=74.22%, confidence=64.002%, sensitivity=0.073, robustness=-0.029, step_sim=99.960\n",
      "\n",
      "Current target cell:6 / current target node:2\n",
      "*Train* [2022-11-02 08:34:52] Ep:0 [000/391] Time 0.46 (0.46) Data 0.31 (0.31) Base [Loss 3.039 (3.039)  Prec@1 17.19 (17.19) Prec@5 62.50 (62.50)]\n",
      "*Train* [2022-11-02 08:35:12] Ep:0 [200/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.781 (0.875)  Prec@1 73.44 (70.41) Prec@5 95.31 (96.98)]\n",
      "*Train* [2022-11-02 08:35:31] Ep:0 [390/391] Time 0.08 (0.10) Data 0.00 (0.00) Base [Loss 0.861 (0.813)  Prec@1 70.00 (72.23) Prec@5 97.50 (97.61)]\n",
      "Ep:0 ends : loss=0.81, accuracy@1=72.23%, accuracy@5=97.61%\n",
      "*Train* [2022-11-02 08:35:31] Ep:1 [000/391] Time 0.41 (0.41) Data 0.26 (0.26) Base [Loss 0.619 (0.619)  Prec@1 79.69 (79.69) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-02 08:35:52] Ep:1 [200/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.530 (0.693)  Prec@1 78.12 (76.07) Prec@5 100.00 (98.51)]\n",
      "*Train* [2022-11-02 08:36:13] Ep:1 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.727 (0.694)  Prec@1 72.50 (76.13) Prec@5 100.00 (98.43)]\n",
      "Ep:1 ends : loss=0.69, accuracy@1=76.13%, accuracy@5=98.43%\n",
      "Found best op for target cell:6 / target node:2\n",
      ": Structure(4 nodes with |avg_pool_3x3~0|+|skip_connect~0|none~1|+|none~0|none~1|skip_connect~2|) with accuracy=76.56%, confidence=63.677%, sensitivity=0.102, robustness=-0.028, step_sim=99.949\n",
      "\n",
      "Current target cell:6 / current target node:3\n",
      "*Train* [2022-11-02 08:36:32] Ep:0 [000/391] Time 0.41 (0.41) Data 0.26 (0.26) Base [Loss 0.687 (0.687)  Prec@1 78.12 (78.12) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:36:53] Ep:0 [200/391] Time 0.07 (0.10) Data 0.00 (0.00) Base [Loss 1.171 (0.839)  Prec@1 70.31 (71.33) Prec@5 92.19 (97.41)]\n",
      "*Train* [2022-11-02 08:37:14] Ep:0 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.779 (0.778)  Prec@1 72.50 (73.25) Prec@5 95.00 (97.87)]\n",
      "Ep:0 ends : loss=0.78, accuracy@1=73.25%, accuracy@5=97.87%\n",
      "*Train* [2022-11-02 08:37:15] Ep:1 [000/391] Time 0.37 (0.37) Data 0.29 (0.29) Base [Loss 0.820 (0.820)  Prec@1 78.12 (78.12) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:37:35] Ep:1 [200/391] Time 0.08 (0.10) Data 0.00 (0.00) Base [Loss 0.730 (0.681)  Prec@1 76.56 (76.48) Prec@5 100.00 (98.66)]\n",
      "*Train* [2022-11-02 08:37:58] Ep:1 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.514 (0.678)  Prec@1 85.00 (76.83) Prec@5 100.00 (98.57)]\n",
      "Ep:1 ends : loss=0.68, accuracy@1=76.83%, accuracy@5=98.57%\n",
      "Found best op for target cell:6 / target node:3\n",
      ": Structure(4 nodes with |avg_pool_3x3~0|+|skip_connect~0|none~1|+|none~0|none~1|skip_connect~2|) with accuracy=74.02%, confidence=62.758%, sensitivity=0.098, robustness=-0.033, step_sim=99.941\n",
      "\n",
      "\n",
      " Searching with a cell #7\n",
      "\n",
      "Current target cell:7 / current target node:1\n",
      "*Train* [2022-11-02 08:39:49] Ep:0 [000/391] Time 0.38 (0.38) Data 0.27 (0.27) Base [Loss 0.643 (0.643)  Prec@1 79.69 (79.69) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-02 08:40:13] Ep:0 [200/391] Time 0.14 (0.12) Data 0.00 (0.00) Base [Loss 0.684 (0.860)  Prec@1 79.69 (70.79) Prec@5 98.44 (97.00)]\n",
      "*Train* [2022-11-02 08:40:34] Ep:0 [390/391] Time 0.20 (0.11) Data 0.00 (0.00) Base [Loss 1.007 (0.781)  Prec@1 60.00 (73.19) Prec@5 100.00 (97.72)]\n",
      "Ep:0 ends : loss=0.78, accuracy@1=73.19%, accuracy@5=97.72%\n",
      "*Train* [2022-11-02 08:40:34] Ep:1 [000/391] Time 0.38 (0.38) Data 0.29 (0.29) Base [Loss 0.468 (0.468)  Prec@1 81.25 (81.25) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-02 08:40:55] Ep:1 [200/391] Time 0.12 (0.10) Data 0.00 (0.00) Base [Loss 0.626 (0.663)  Prec@1 82.81 (76.97) Prec@5 96.88 (98.75)]\n",
      "*Train* [2022-11-02 08:41:15] Ep:1 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.596 (0.661)  Prec@1 72.50 (77.10) Prec@5 100.00 (98.66)]\n",
      "Ep:1 ends : loss=0.66, accuracy@1=77.10%, accuracy@5=98.66%\n",
      "Found best op for target cell:7 / target node:1\n",
      ": Structure(4 nodes with |nor_conv_3x3~0|+|none~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=73.83%, confidence=63.135%, sensitivity=0.095, robustness=-0.037, step_sim=99.915\n",
      "\n",
      "Current target cell:7 / current target node:2\n",
      "*Train* [2022-11-02 08:41:19] Ep:0 [000/391] Time 0.42 (0.42) Data 0.28 (0.28) Base [Loss 3.743 (3.743)  Prec@1 6.25 (6.25) Prec@5 45.31 (45.31)]\n",
      "*Train* [2022-11-02 08:41:39] Ep:0 [200/391] Time 0.12 (0.10) Data 0.00 (0.00) Base [Loss 0.695 (0.855)  Prec@1 75.00 (70.62) Prec@5 100.00 (96.85)]\n",
      "*Train* [2022-11-02 08:41:59] Ep:0 [390/391] Time 0.12 (0.10) Data 0.00 (0.00) Base [Loss 0.596 (0.772)  Prec@1 72.50 (73.29) Prec@5 97.50 (97.72)]\n",
      "Ep:0 ends : loss=0.77, accuracy@1=73.29%, accuracy@5=97.72%\n",
      "*Train* [2022-11-02 08:41:59] Ep:1 [000/391] Time 0.51 (0.51) Data 0.31 (0.31) Base [Loss 0.767 (0.767)  Prec@1 76.56 (76.56) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:42:18] Ep:1 [200/391] Time 0.07 (0.10) Data 0.00 (0.00) Base [Loss 0.603 (0.657)  Prec@1 76.56 (77.32) Prec@5 98.44 (98.58)]\n",
      "*Train* [2022-11-02 08:42:39] Ep:1 [390/391] Time 0.07 (0.10) Data 0.00 (0.00) Base [Loss 0.928 (0.660)  Prec@1 67.50 (77.04) Prec@5 97.50 (98.67)]\n",
      "Ep:1 ends : loss=0.66, accuracy@1=77.04%, accuracy@5=98.67%\n",
      "Found best op for target cell:7 / target node:2\n",
      ": Structure(4 nodes with |nor_conv_3x3~0|+|none~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=74.02%, confidence=64.046%, sensitivity=0.104, robustness=-0.036, step_sim=99.937\n",
      "\n",
      "Current target cell:7 / current target node:3\n",
      "*Train* [2022-11-02 08:43:04] Ep:0 [000/391] Time 0.40 (0.40) Data 0.26 (0.26) Base [Loss 0.780 (0.780)  Prec@1 75.00 (75.00) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-02 08:43:25] Ep:0 [200/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.602 (0.815)  Prec@1 78.12 (72.01) Prec@5 100.00 (97.48)]\n",
      "*Train* [2022-11-02 08:43:42] Ep:0 [390/391] Time 0.12 (0.10) Data 0.00 (0.00) Base [Loss 0.561 (0.749)  Prec@1 80.00 (74.47) Prec@5 100.00 (98.09)]\n",
      "Ep:0 ends : loss=0.75, accuracy@1=74.47%, accuracy@5=98.09%\n",
      "*Train* [2022-11-02 08:43:42] Ep:1 [000/391] Time 0.39 (0.39) Data 0.31 (0.31) Base [Loss 0.758 (0.758)  Prec@1 75.00 (75.00) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-02 08:43:58] Ep:1 [200/391] Time 0.07 (0.08) Data 0.00 (0.00) Base [Loss 0.688 (0.663)  Prec@1 78.12 (77.01) Prec@5 96.88 (98.66)]\n",
      "*Train* [2022-11-02 08:44:18] Ep:1 [390/391] Time 0.13 (0.09) Data 0.00 (0.00) Base [Loss 0.727 (0.660)  Prec@1 77.50 (77.09) Prec@5 95.00 (98.62)]\n",
      "Ep:1 ends : loss=0.66, accuracy@1=77.09%, accuracy@5=98.62%\n",
      "Found best op for target cell:7 / target node:3\n",
      ": Structure(4 nodes with |nor_conv_3x3~0|+|none~0|skip_connect~1|+|nor_conv_3x3~0|nor_conv_3x3~1|avg_pool_3x3~2|) with accuracy=74.41%, confidence=64.567%, sensitivity=0.120, robustness=-0.043, step_sim=99.939\n",
      "\n",
      "\n",
      " Searching with a cell #8\n",
      "\n",
      "Current target cell:8 / current target node:1\n",
      "*Train* [2022-11-02 08:46:14] Ep:0 [000/391] Time 0.41 (0.41) Data 0.26 (0.26) Base [Loss 0.807 (0.807)  Prec@1 73.44 (73.44) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-02 08:46:36] Ep:0 [200/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.704 (0.815)  Prec@1 75.00 (71.46) Prec@5 100.00 (97.54)]\n",
      "*Train* [2022-11-02 08:46:55] Ep:0 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.838 (0.747)  Prec@1 60.00 (74.27) Prec@5 100.00 (98.15)]\n",
      "Ep:0 ends : loss=0.75, accuracy@1=74.27%, accuracy@5=98.15%\n",
      "*Train* [2022-11-02 08:46:56] Ep:1 [000/391] Time 0.35 (0.35) Data 0.26 (0.26) Base [Loss 0.526 (0.526)  Prec@1 79.69 (79.69) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:47:14] Ep:1 [200/391] Time 0.07 (0.09) Data 0.00 (0.00) Base [Loss 0.536 (0.648)  Prec@1 78.12 (77.68) Prec@5 100.00 (98.59)]\n",
      "*Train* [2022-11-02 08:47:31] Ep:1 [390/391] Time 0.07 (0.09) Data 0.00 (0.00) Base [Loss 1.025 (0.645)  Prec@1 65.00 (77.84) Prec@5 100.00 (98.67)]\n",
      "Ep:1 ends : loss=0.64, accuracy@1=77.84%, accuracy@5=98.67%\n",
      "Found best op for target cell:8 / target node:1\n",
      ": Structure(4 nodes with |avg_pool_3x3~0|+|none~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=77.15%, confidence=67.074%, sensitivity=0.084, robustness=-0.035, step_sim=99.947\n",
      "\n",
      "Current target cell:8 / current target node:2\n",
      "*Train* [2022-11-02 08:47:35] Ep:0 [000/391] Time 0.36 (0.36) Data 0.27 (0.27) Base [Loss 2.737 (2.737)  Prec@1 14.06 (14.06) Prec@5 64.06 (64.06)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Train* [2022-11-02 08:47:55] Ep:0 [200/391] Time 0.12 (0.10) Data 0.00 (0.00) Base [Loss 0.671 (0.742)  Prec@1 76.56 (74.33) Prec@5 100.00 (98.03)]\n",
      "*Train* [2022-11-02 08:48:18] Ep:0 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.865 (0.701)  Prec@1 72.50 (75.67) Prec@5 100.00 (98.32)]\n",
      "Ep:0 ends : loss=0.70, accuracy@1=75.67%, accuracy@5=98.32%\n",
      "*Train* [2022-11-02 08:48:19] Ep:1 [000/391] Time 0.40 (0.40) Data 0.30 (0.30) Base [Loss 0.525 (0.525)  Prec@1 84.38 (84.38) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-02 08:48:39] Ep:1 [200/391] Time 0.12 (0.10) Data 0.00 (0.00) Base [Loss 0.598 (0.638)  Prec@1 82.81 (78.50) Prec@5 100.00 (98.70)]\n",
      "*Train* [2022-11-02 08:48:58] Ep:1 [390/391] Time 0.12 (0.10) Data 0.00 (0.00) Base [Loss 0.748 (0.639)  Prec@1 70.00 (78.26) Prec@5 97.50 (98.65)]\n",
      "Ep:1 ends : loss=0.64, accuracy@1=78.26%, accuracy@5=98.65%\n",
      "Found best op for target cell:8 / target node:2\n",
      ": Structure(4 nodes with |avg_pool_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=75.39%, confidence=65.072%, sensitivity=0.106, robustness=-0.057, step_sim=99.949\n",
      "\n",
      "Current target cell:8 / current target node:3\n",
      "*Train* [2022-11-02 08:49:19] Ep:0 [000/391] Time 0.35 (0.35) Data 0.26 (0.26) Base [Loss 3.143 (3.143)  Prec@1 12.50 (12.50) Prec@5 59.38 (59.38)]\n",
      "*Train* [2022-11-02 08:49:41] Ep:0 [200/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.591 (0.774)  Prec@1 75.00 (73.21) Prec@5 98.44 (97.50)]\n",
      "*Train* [2022-11-02 08:50:00] Ep:0 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.765 (0.733)  Prec@1 75.00 (74.80) Prec@5 100.00 (97.94)]\n",
      "Ep:0 ends : loss=0.73, accuracy@1=74.80%, accuracy@5=97.94%\n",
      "*Train* [2022-11-02 08:50:01] Ep:1 [000/391] Time 0.42 (0.42) Data 0.33 (0.33) Base [Loss 0.908 (0.908)  Prec@1 71.88 (71.88) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:50:19] Ep:1 [200/391] Time 0.08 (0.09) Data 0.00 (0.00) Base [Loss 0.634 (0.650)  Prec@1 82.81 (77.51) Prec@5 98.44 (98.73)]\n",
      "*Train* [2022-11-02 08:50:41] Ep:1 [390/391] Time 0.13 (0.10) Data 0.00 (0.00) Base [Loss 0.600 (0.649)  Prec@1 82.50 (77.55) Prec@5 97.50 (98.76)]\n",
      "Ep:1 ends : loss=0.65, accuracy@1=77.55%, accuracy@5=98.76%\n",
      "Found best op for target cell:8 / target node:3\n",
      ": Structure(4 nodes with |avg_pool_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|nor_conv_3x3~0|nor_conv_1x1~1|skip_connect~2|) with accuracy=74.80%, confidence=64.729%, sensitivity=0.125, robustness=-0.037, step_sim=99.950\n",
      "\n",
      "\n",
      " Searching with a cell #9\n",
      "\n",
      "Current target cell:9 / current target node:1\n",
      "*Train* [2022-11-02 08:52:48] Ep:0 [000/391] Time 0.45 (0.45) Data 0.30 (0.30) Base [Loss 0.590 (0.590)  Prec@1 78.12 (78.12) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:53:15] Ep:0 [200/391] Time 0.14 (0.14) Data 0.00 (0.00) Base [Loss 0.710 (0.745)  Prec@1 78.12 (74.11) Prec@5 98.44 (98.11)]\n",
      "*Train* [2022-11-02 08:53:34] Ep:0 [390/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.940 (0.701)  Prec@1 62.50 (75.72) Prec@5 97.50 (98.32)]\n",
      "Ep:0 ends : loss=0.70, accuracy@1=75.72%, accuracy@5=98.32%\n",
      "*Train* [2022-11-02 08:53:35] Ep:1 [000/391] Time 0.39 (0.39) Data 0.30 (0.30) Base [Loss 0.697 (0.697)  Prec@1 76.56 (76.56) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-02 08:54:00] Ep:1 [200/391] Time 0.14 (0.13) Data 0.00 (0.00) Base [Loss 0.799 (0.620)  Prec@1 75.00 (78.86) Prec@5 98.44 (98.76)]\n",
      "*Train* [2022-11-02 08:54:19] Ep:1 [390/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.717 (0.629)  Prec@1 72.50 (78.48) Prec@5 100.00 (98.70)]\n",
      "Ep:1 ends : loss=0.63, accuracy@1=78.48%, accuracy@5=98.70%\n",
      "Found best op for target cell:9 / target node:1\n",
      ": Structure(4 nodes with |avg_pool_3x3~0|+|none~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=72.66%, confidence=62.331%, sensitivity=0.105, robustness=-0.050, step_sim=99.949\n",
      "\n",
      "Current target cell:9 / current target node:2\n",
      "*Train* [2022-11-02 08:54:24] Ep:0 [000/391] Time 0.43 (0.43) Data 0.28 (0.28) Base [Loss 0.678 (0.678)  Prec@1 75.00 (75.00) Prec@5 95.31 (95.31)]\n",
      "*Train* [2022-11-02 08:54:45] Ep:0 [200/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.784 (0.744)  Prec@1 79.69 (74.46) Prec@5 98.44 (97.78)]\n",
      "*Train* [2022-11-02 08:55:06] Ep:0 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.713 (0.697)  Prec@1 80.00 (76.07) Prec@5 97.50 (98.24)]\n",
      "Ep:0 ends : loss=0.70, accuracy@1=76.07%, accuracy@5=98.24%\n",
      "*Train* [2022-11-02 08:55:07] Ep:1 [000/391] Time 0.39 (0.39) Data 0.30 (0.30) Base [Loss 0.640 (0.640)  Prec@1 81.25 (81.25) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-02 08:55:28] Ep:1 [200/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.647 (0.635)  Prec@1 78.12 (78.24) Prec@5 98.44 (98.64)]\n",
      "*Train* [2022-11-02 08:55:47] Ep:1 [390/391] Time 0.08 (0.10) Data 0.00 (0.00) Base [Loss 0.539 (0.624)  Prec@1 85.00 (78.32) Prec@5 100.00 (98.71)]\n",
      "Ep:1 ends : loss=0.62, accuracy@1=78.32%, accuracy@5=98.71%\n",
      "Found best op for target cell:9 / target node:2\n",
      ": Structure(4 nodes with |avg_pool_3x3~0|+|nor_conv_1x1~0|skip_connect~1|+|none~0|none~1|skip_connect~2|) with accuracy=75.59%, confidence=67.377%, sensitivity=0.109, robustness=-0.039, step_sim=99.944\n",
      "\n",
      "Current target cell:9 / current target node:3\n",
      "*Train* [2022-11-02 08:56:11] Ep:0 [000/391] Time 0.39 (0.39) Data 0.31 (0.31) Base [Loss 0.723 (0.723)  Prec@1 68.75 (68.75) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-02 08:56:31] Ep:0 [200/391] Time 0.12 (0.10) Data 0.00 (0.00) Base [Loss 0.668 (0.709)  Prec@1 75.00 (76.16) Prec@5 100.00 (98.12)]\n",
      "*Train* [2022-11-02 08:56:51] Ep:0 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.746 (0.688)  Prec@1 75.00 (76.56) Prec@5 97.50 (98.29)]\n",
      "Ep:0 ends : loss=0.69, accuracy@1=76.56%, accuracy@5=98.29%\n",
      "*Train* [2022-11-02 08:56:52] Ep:1 [000/391] Time 0.40 (0.40) Data 0.31 (0.31) Base [Loss 0.412 (0.412)  Prec@1 84.38 (84.38) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-02 08:57:19] Ep:1 [200/391] Time 0.13 (0.14) Data 0.00 (0.00) Base [Loss 0.481 (0.620)  Prec@1 87.50 (78.81) Prec@5 100.00 (98.80)]\n",
      "*Train* [2022-11-02 08:57:44] Ep:1 [390/391] Time 0.12 (0.13) Data 0.00 (0.00) Base [Loss 0.645 (0.626)  Prec@1 77.50 (78.44) Prec@5 100.00 (98.83)]\n",
      "Ep:1 ends : loss=0.63, accuracy@1=78.44%, accuracy@5=98.83%\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "start_time, search_time, epoch_time, total_epoch = (\n",
    "    time.time(),\n",
    "    AverageMeter(),\n",
    "    AverageMeter(),\n",
    "    config.epochs + config.warmup,\n",
    ")\n",
    "\n",
    "################# initialize\n",
    "cells = []\n",
    "for m in network.modules():\n",
    "    if isinstance(m, SearchCell):\n",
    "        cells.append(m)\n",
    "num_cells = len(cells)\n",
    "print(\"total number of nodes:{}\".format(num_cells*xargs.max_nodes))\n",
    "        \n",
    "op_names = deepcopy(cells[0].op_names)\n",
    "op_names_wo_none = deepcopy(op_names)\n",
    "if \"none\" in op_names_wo_none:\n",
    "    op_names_wo_none.remove(\"none\")\n",
    "\n",
    "genotypes = []\n",
    "for i in range(1, xargs.max_nodes):\n",
    "    xlist = []\n",
    "    for j in range(i):\n",
    "        node_str = \"{:}<-{:}\".format(i, j)\n",
    "        if i-j==1:\n",
    "            op_name = \"skip_connect\"\n",
    "        else:\n",
    "            op_name = \"none\"\n",
    "        xlist.append((op_name, j))\n",
    "    genotypes.append(tuple(xlist))\n",
    "init_arch = Structure(genotypes)\n",
    "\n",
    "for c in cells:\n",
    "    c.arch_cache = init_arch\n",
    "\n",
    "### gen possible connections of a target node\n",
    "possible_connections = {}\n",
    "for target_node_idx in range(1,xargs.max_nodes):\n",
    "    possible_connections[target_node_idx] = list()\n",
    "    xlists = []\n",
    "    for src_node in range(target_node_idx):\n",
    "        node_str = \"{:}<-{:}\".format(target_node_idx, src_node)\n",
    "        # select possible ops\n",
    "#         if target_node_idx - src_node == 1:\n",
    "#             op_names_tmp = op_names_wo_none\n",
    "#         else:\n",
    "#             op_names_tmp = op_names\n",
    "        op_names_tmp = op_names\n",
    "            \n",
    "        if len(xlists) == 0: # initial iteration\n",
    "            for op_name in op_names_tmp:\n",
    "                xlists.append([(op_name, src_node)])\n",
    "        else:\n",
    "            new_xlists = []\n",
    "            for op_name in op_names_tmp:\n",
    "                for xlist in xlists:\n",
    "                    new_xlist = deepcopy(xlist)\n",
    "                    new_xlist.append((op_name, src_node))\n",
    "                    new_xlists.append(new_xlist)\n",
    "            xlists = new_xlists\n",
    "    for xlist in xlists:\n",
    "        selected_ops = []\n",
    "        for l in xlist:\n",
    "            selected_ops.append(l[0])\n",
    "        if sum(np.array(selected_ops) == \"none\") == len(selected_ops):\n",
    "            continue\n",
    "        possible_connections[target_node_idx].append(tuple(xlist))\n",
    "    print(\"target_node:{}\".format(target_node_idx), len(possible_connections[target_node_idx]))\n",
    "        \n",
    "### train while generating random architectures by mutating connections of a target node\n",
    "\n",
    "for arch_loop in range(3):\n",
    "    for target_cell_idx in range(num_cells):\n",
    "        for cell_loop in range(1):\n",
    "#             network.module.classifier.reset_parameters()\n",
    "            target_cell = cells[target_cell_idx]\n",
    "            print(\"\\n\\n Searching with a cell #{}\".format(target_cell_idx))\n",
    "            for target_node_idx in range(1,xargs.max_nodes):\n",
    "                current_genotypes,_ = target_cell.arch_cache.tolist(None)\n",
    "                print(\"\\nCurrent target cell:{} / current target node:{}\".format(target_cell_idx, target_node_idx))\n",
    "                ####\n",
    "                for src_node_idx in range(target_node_idx):\n",
    "                    node_str = \"{:}<-{:}\".format(target_node_idx, src_node_idx)\n",
    "                    for m in target_cell.edges[node_str].modules():\n",
    "                        if hasattr(m, 'reset_parameters'):\n",
    "                            m.reset_parameters()\n",
    "                ####\n",
    "                ## training\n",
    "                for ep in range(2):\n",
    "                    data_time, batch_time = AverageMeter(), AverageMeter()\n",
    "                    base_losses, base_top1, base_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "                    network.train()\n",
    "                    end = time.time()\n",
    "                    print_freq = 200\n",
    "                    for step, (base_inputs, base_targets, arch_inputs, arch_targets) in enumerate(search_loader):\n",
    "                        ######### random generation\n",
    "                        genotypes = deepcopy(current_genotypes)\n",
    "                        connection = random.choice(possible_connections[target_node_idx])\n",
    "                        genotypes[target_node_idx-1] = connection\n",
    "                        arch = Structure(genotypes)\n",
    "                        target_cell.arch_cache = arch\n",
    "\n",
    "                        ######### forward/backward/optim\n",
    "                        base_targets = base_targets.cuda(non_blocking=True)\n",
    "                        arch_targets = arch_targets.cuda(non_blocking=True)\n",
    "                        # measure data loading time\n",
    "                        data_time.update(time.time() - end)\n",
    "                        w_optimizer.zero_grad()\n",
    "                        _, logits = network(base_inputs)\n",
    "                        base_loss = criterion(logits, base_targets)\n",
    "                        base_loss.backward()\n",
    "                        nn.utils.clip_grad_norm_(network.parameters(), 5)\n",
    "                        w_optimizer.step()\n",
    "\n",
    "                        ######### logging\n",
    "                        base_prec1, base_prec5 = obtain_accuracy(logits.data, base_targets.data, topk=(1, 5))\n",
    "                        base_losses.update(base_loss.item(), base_inputs.size(0))\n",
    "                        base_top1.update(base_prec1.item(), base_inputs.size(0))\n",
    "                        base_top5.update(base_prec5.item(), base_inputs.size(0))\n",
    "                        batch_time.update(time.time() - end)\n",
    "                        end = time.time()\n",
    "                        if step % print_freq == 0 or step + 1 == len(search_loader):\n",
    "                            Sstr = (\"*Train* \"+ time_string()+\" Ep:{:} [{:03d}/{:03d}]\".format(ep, step, len(search_loader)))\n",
    "                            Tstr = \"Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\".format(batch_time=batch_time, data_time=data_time)\n",
    "                            Wstr = \"Base [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\".format(loss=base_losses, top1=base_top1, top5=base_top5)\n",
    "                            logger.log(Sstr + \" \" + Tstr + \" \" + Wstr)\n",
    "\n",
    "                    logger.log(\"Ep:{:} ends : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\".format(ep, base_losses.avg, base_top1.avg, base_top5.avg))\n",
    "                ## evaluation\n",
    "                network.train()\n",
    "                archs, metric_accs, metric_confidences, metric_sensitivities, metric_robustnesses, metric_step_sims = [], [], [], [], [], []\n",
    "                loader_iter = iter(valid_loader)\n",
    "                for connection in possible_connections[target_node_idx]:\n",
    "                    ###### traverse over possible archs\n",
    "                    genotypes = deepcopy(current_genotypes)\n",
    "                    genotypes[target_node_idx-1] = connection\n",
    "                    arch = Structure(genotypes)\n",
    "                    target_cell.arch_cache = arch\n",
    "                    ###### measure metrics\n",
    "                    try:\n",
    "                        inputs, targets = next(loader_iter)\n",
    "                    except:\n",
    "                        loader_iter = iter(valid_loader)\n",
    "                        inputs, targets = next(loader_iter)\n",
    "                    inputs, targets = inputs.cuda(non_blocking=True), targets.cuda(non_blocking=True)\n",
    "                    valid_acc, confidence, sensitivity, robustness = acc_confidence_robustness_metrics(network, inputs, targets)\n",
    "                    step_sim = step_sim_metric(network, criterion, inputs, targets)\n",
    "                    archs.append(arch)\n",
    "                    metric_accs.append(valid_acc)\n",
    "                    metric_confidences.append(confidence)\n",
    "                    metric_sensitivities.append(sensitivity)\n",
    "                    metric_robustnesses.append(robustness)\n",
    "                    metric_step_sims.append(step_sim)\n",
    "                rank_accs, rank_confidences, rank_sensitivities, rank_robustnesses, rank_step_sims = stats.rankdata(metric_accs), stats.rankdata(metric_confidences), stats.rankdata(metric_sensitivities), stats.rankdata(metric_robustnesses), stats.rankdata(metric_step_sims)\n",
    "                l = len(rank_accs)\n",
    "                rank_agg = np.log(rank_accs/l)+np.log(rank_confidences/l)+np.log(rank_sensitivities/l)+np.log(rank_robustnesses/l)+np.log(rank_step_sims/l)\n",
    "    #             rank_agg = np.log(rank_accs/l)+np.log(rank_confidences/l)+np.log(rank_sensitivities/l)+np.log(rank_step_sims/l)\n",
    "                best_idx = np.argmax(rank_agg)\n",
    "                best_arch, best_acc, best_conf, best_sensitivity, best_robust, best_step_sim = archs[best_idx], metric_accs[best_idx], metric_confidences[best_idx], metric_sensitivities[best_idx], metric_robustnesses[best_idx], metric_step_sims[best_idx]\n",
    "                logger.log(\"Found best op for target cell:{} / target node:{}\".format(target_cell_idx, target_node_idx))\n",
    "                logger.log(\": {:} with accuracy={:.2f}%, confidence={:.3f}%, sensitivity={:.3f}, robustness={:.3f}, step_sim={:.3f}\".format(best_arch, best_acc, best_conf, best_sensitivity, best_robust, best_step_sim))\n",
    "                target_cell.arch_cache = best_arch\n",
    "            \n",
    "best_archs = []\n",
    "for c in cells:\n",
    "    best_archs.append(c.arch_cache)\n",
    "    \n",
    "torch.save({\"model\":search_model.state_dict(), \"best_archs\":best_archs}, os.path.join(xargs.save_dir, \"output.pth\"))\n",
    "\n",
    "for m in search_model.modules():\n",
    "    if isinstance(m, SearchCell):\n",
    "        logger.log(m.arch_cache)\n",
    "\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bde3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(rank_confidences,rank_accs)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(rank_sensitivities,rank_accs)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(rank_robustnesses,rank_accs)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(rank_step_sims,rank_accs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da32ec",
   "metadata": {},
   "source": [
    "# Train a found model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ae460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_output = torch.load(os.path.join(xargs.save_dir, \"output.pth\"))\n",
    "print(args)\n",
    "args.save_dir = os.path.join(xargs.save_dir, \"train\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed27598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c02f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = prepare_logger(args)\n",
    "\n",
    "# cifar_train_config_path = \"./MY.config\"\n",
    "cifar_train_config_path = \"../configs/nas-benchmark/CIFAR.config\"\n",
    "###\n",
    "train_data, test_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n",
    "config = load_config(cifar_train_config_path, {\"class_num\": class_num, \"xshape\": xshape}, logger)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            train_data,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=xargs.workers,\n",
    "            pin_memory=True,)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            test_data,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=xargs.workers,\n",
    "            pin_memory=True,)\n",
    "\n",
    "# search_loader, _, valid_loader = get_nas_search_loaders(train_data,\n",
    "#                                                         valid_data,\n",
    "#                                                         xargs.dataset,\n",
    "#                                                         \"../configs/nas-benchmark/\",\n",
    "#                                                         (config.batch_size, config.batch_size),\n",
    "#                                                         xargs.workers)\n",
    "logger.log(\"||||||| {:10s} ||||||| Train-Loader-Num={:}, Test-Loader-Num={:}, batch size={:}\".format(\n",
    "            xargs.dataset, len(train_loader), len(test_loader), config.batch_size))\n",
    "logger.log(\"||||||| {:10s} ||||||| Config={:}\".format(xargs.dataset, config))\n",
    "\n",
    "search_space = get_search_spaces(\"cell\", xargs.search_space_name)\n",
    "model_config = dict2config(\n",
    "    {\n",
    "        \"name\": \"RANDOM\",\n",
    "        \"C\": xargs.channel,\n",
    "        \"N\": xargs.num_cells,\n",
    "        \"max_nodes\": xargs.max_nodes,\n",
    "        \"num_classes\": class_num,\n",
    "        \"space\": search_space,\n",
    "        \"affine\": False,\n",
    "        \"track_running_stats\": True, # true for eval\n",
    "    },\n",
    "    None,\n",
    ")\n",
    "search_model = get_cell_based_tiny_net(model_config)\n",
    "\n",
    "### load\n",
    "# trained_output = torch.load(os.path.join(xargs.save_dir, \"output.pth\"))\n",
    "# search_model.load_state_dict(trained_output['model'], strict=False)\n",
    "best_archs = trained_output['best_archs']\n",
    "i=0\n",
    "for m in search_model.modules():\n",
    "    if isinstance(m, SearchCell):\n",
    "        m.arch_cache = best_archs[i]\n",
    "        i += 1\n",
    "for m in network.modules():\n",
    "    if isinstance(m, SearchCell):\n",
    "        print(m.arch_cache)\n",
    "###\n",
    "\n",
    "w_optimizer, w_scheduler, criterion = get_optim_scheduler(search_model.parameters(), config)\n",
    "\n",
    "logger.log(\"w-optimizer : {:}\".format(w_optimizer))\n",
    "logger.log(\"w-scheduler : {:}\".format(w_scheduler))\n",
    "logger.log(\"criterion   : {:}\".format(criterion))\n",
    "\n",
    "network, criterion = torch.nn.DataParallel(search_model).cuda(), criterion.cuda()\n",
    "\n",
    "last_info, model_base_path, model_best_path = (\n",
    "    logger.path(\"info\"),\n",
    "    logger.path(\"model\"),\n",
    "    logger.path(\"best\"),\n",
    ")\n",
    "\n",
    "start_epoch, valid_accuracies, genotypes = 0, {\"best\": -1}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964fcb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search_func_one_arch(xloader, network, criterion, scheduler, w_optimizer, epoch_str, print_freq, logger):\n",
    "#     data_time, batch_time = AverageMeter(), AverageMeter()\n",
    "#     base_losses, base_top1, base_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "#     network.train()\n",
    "#     end = time.time()\n",
    "#     for step, (base_inputs, base_targets, arch_inputs, arch_targets) in enumerate(\n",
    "#         xloader\n",
    "#     ):\n",
    "#         scheduler.update(None, 1.0 * step / len(xloader))\n",
    "#         base_targets = base_targets.cuda(non_blocking=True)\n",
    "#         arch_targets = arch_targets.cuda(non_blocking=True)\n",
    "#         # measure data loading time\n",
    "#         data_time.update(time.time() - end)\n",
    "\n",
    "#         w_optimizer.zero_grad()\n",
    "#         _, logits = network(base_inputs)\n",
    "#         base_loss = criterion(logits, base_targets)\n",
    "#         base_loss.backward()\n",
    "#         nn.utils.clip_grad_norm_(network.parameters(), 5)\n",
    "#         w_optimizer.step()\n",
    "#         # record\n",
    "#         base_prec1, base_prec5 = obtain_accuracy(\n",
    "#             logits.data, base_targets.data, topk=(1, 5)\n",
    "#         )\n",
    "#         base_losses.update(base_loss.item(), base_inputs.size(0))\n",
    "#         base_top1.update(base_prec1.item(), base_inputs.size(0))\n",
    "#         base_top5.update(base_prec5.item(), base_inputs.size(0))\n",
    "\n",
    "#         # measure elapsed time\n",
    "#         batch_time.update(time.time() - end)\n",
    "#         end = time.time()\n",
    "\n",
    "#         if step % print_freq == 0 or step + 1 == len(xloader):\n",
    "#             Sstr = (\n",
    "#                 \"*SEARCH* \"\n",
    "#                 + time_string()\n",
    "#                 + \" [{:}][{:03d}/{:03d}]\".format(epoch_str, step, len(xloader))\n",
    "#             )\n",
    "#             Tstr = \"Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\".format(\n",
    "#                 batch_time=batch_time, data_time=data_time\n",
    "#             )\n",
    "#             Wstr = \"Base [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\".format(\n",
    "#                 loss=base_losses, top1=base_top1, top5=base_top5\n",
    "#             )\n",
    "#             logger.log(Sstr + \" \" + Tstr + \" \" + Wstr)\n",
    "#     return base_losses.avg, base_top1.avg, base_top5.avg\n",
    "\n",
    "def train_func_one_arch(xloader, network, criterion, scheduler, w_optimizer, epoch_str, print_freq, logger):\n",
    "    data_time, batch_time = AverageMeter(), AverageMeter()\n",
    "    base_losses, base_top1, base_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    network.train()\n",
    "    end = time.time()\n",
    "    for step, (base_inputs, base_targets) in enumerate(\n",
    "        xloader\n",
    "    ):\n",
    "        scheduler.update(None, 1.0 * step / len(xloader))\n",
    "        base_targets = base_targets.cuda(non_blocking=True)\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        w_optimizer.zero_grad()\n",
    "        _, logits = network(base_inputs)\n",
    "        base_loss = criterion(logits, base_targets)\n",
    "        base_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(network.parameters(), 5)\n",
    "        w_optimizer.step()\n",
    "        # record\n",
    "        base_prec1, base_prec5 = obtain_accuracy(\n",
    "            logits.data, base_targets.data, topk=(1, 5)\n",
    "        )\n",
    "        base_losses.update(base_loss.item(), base_inputs.size(0))\n",
    "        base_top1.update(base_prec1.item(), base_inputs.size(0))\n",
    "        base_top5.update(base_prec5.item(), base_inputs.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % print_freq == 0 or step + 1 == len(xloader):\n",
    "            Sstr = (\n",
    "                \"*SEARCH* \"\n",
    "                + time_string()\n",
    "                + \" [{:}][{:03d}/{:03d}]\".format(epoch_str, step, len(xloader))\n",
    "            )\n",
    "            Tstr = \"Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\".format(\n",
    "                batch_time=batch_time, data_time=data_time\n",
    "            )\n",
    "            Wstr = \"Base [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\".format(\n",
    "                loss=base_losses, top1=base_top1, top5=base_top5\n",
    "            )\n",
    "            logger.log(Sstr + \" \" + Tstr + \" \" + Wstr)\n",
    "    return base_losses.avg, base_top1.avg, base_top5.avg\n",
    "\n",
    "def valid_func_one_arch(xloader, network, criterion):\n",
    "    data_time, batch_time = AverageMeter(), AverageMeter()\n",
    "    arch_losses, arch_top1, arch_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    network.eval()\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for step, (arch_inputs, arch_targets) in enumerate(xloader):\n",
    "            arch_targets = arch_targets.cuda(non_blocking=True)\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "            # prediction\n",
    "\n",
    "#             network.module.random_genotype_per_cell(True)\n",
    "            _, logits = network(arch_inputs)\n",
    "            arch_loss = criterion(logits, arch_targets)\n",
    "            # record\n",
    "            arch_prec1, arch_prec5 = obtain_accuracy(\n",
    "                logits.data, arch_targets.data, topk=(1, 5)\n",
    "            )\n",
    "            arch_losses.update(arch_loss.item(), arch_inputs.size(0))\n",
    "            arch_top1.update(arch_prec1.item(), arch_inputs.size(0))\n",
    "            arch_top5.update(arch_prec5.item(), arch_inputs.size(0))\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "    return arch_losses.avg, arch_top1.avg, arch_top5.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be07a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time, search_time, epoch_time, total_epoch = (\n",
    "    time.time(),\n",
    "    AverageMeter(),\n",
    "    AverageMeter(),\n",
    "    config.epochs + config.warmup,\n",
    ")\n",
    "for epoch in range(0, total_epoch):\n",
    "    w_scheduler.update(epoch, 0.0)\n",
    "    need_time = \"Time Left: {:}\".format(\n",
    "        convert_secs2time(epoch_time.val * (total_epoch - epoch), True)\n",
    "    )\n",
    "    epoch_str = \"{:03d}-{:03d}\".format(epoch, total_epoch)\n",
    "    logger.log(\n",
    "        \"\\n[Search the {:}-th epoch] {:}, LR={:}\".format(\n",
    "            epoch_str, need_time, min(w_scheduler.get_lr())\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # selected_arch = search_find_best(valid_loader, network, criterion, xargs.select_num)\n",
    "    search_w_loss, search_w_top1, search_w_top5 = train_func_one_arch(\n",
    "        train_loader,\n",
    "        network,\n",
    "        criterion,\n",
    "        w_scheduler,\n",
    "        w_optimizer,\n",
    "        epoch_str,\n",
    "        xargs.print_freq,\n",
    "        logger,\n",
    "    )\n",
    "    search_time.update(time.time() - start_time)\n",
    "    logger.log(\n",
    "        \"[{:}] searching : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%, time-cost={:.1f} s\".format(\n",
    "            epoch_str, search_w_loss, search_w_top1, search_w_top5, search_time.sum\n",
    "        )\n",
    "    )\n",
    "    valid_a_loss, valid_a_top1, valid_a_top5 = valid_func_one_arch(\n",
    "        test_loader, network, criterion\n",
    "    )\n",
    "    logger.log(\n",
    "        \"[{:}] evaluate  : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\".format(\n",
    "            epoch_str, valid_a_loss, valid_a_top1, valid_a_top5\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # check the best accuracy\n",
    "    valid_accuracies[epoch] = valid_a_top1\n",
    "    if valid_a_top1 > valid_accuracies[\"best\"]:\n",
    "        valid_accuracies[\"best\"] = valid_a_top1\n",
    "        find_best = True\n",
    "    else:\n",
    "        find_best = False\n",
    "\n",
    "    # save checkpoint\n",
    "    save_path = save_checkpoint(\n",
    "        {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"args\": deepcopy(xargs),\n",
    "            \"search_model\": search_model.state_dict(),\n",
    "            \"w_optimizer\": w_optimizer.state_dict(),\n",
    "            \"w_scheduler\": w_scheduler.state_dict(),\n",
    "            \"genotypes\": genotypes,\n",
    "            \"valid_accuracies\": valid_accuracies,\n",
    "        },\n",
    "        model_base_path,\n",
    "        logger,\n",
    "    )\n",
    "    last_info = save_checkpoint(\n",
    "        {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"args\": deepcopy(args),\n",
    "            \"last_checkpoint\": save_path,\n",
    "        },\n",
    "        logger.path(\"info\"),\n",
    "        logger,\n",
    "    )\n",
    "    if find_best:\n",
    "        logger.log(\n",
    "            \"<<<--->>> The {:}-th epoch : find the highest validation accuracy : {:.2f}%.\".format(\n",
    "                epoch_str, valid_a_top1\n",
    "            )\n",
    "        )\n",
    "        copy_checkpoint(model_base_path, model_best_path, logger)\n",
    "    if api is not None:\n",
    "        logger.log(\"{:}\".format(api.query_by_arch(genotypes[epoch], \"200\")))\n",
    "    # measure elapsed time\n",
    "    epoch_time.update(time.time() - start_time)\n",
    "    start_time = time.time()\n",
    "\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d00afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_archs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
