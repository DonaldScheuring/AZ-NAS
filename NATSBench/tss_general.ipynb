{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4cc63dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 10:38:29.378315: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-14 10:38:29.423181: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-14 10:38:30.157319: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, glob, random, argparse\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import tqdm\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# XAutoDL \n",
    "from xautodl.config_utils import load_config, dict2config, configure2str\n",
    "from xautodl.datasets import get_datasets, get_nas_search_loaders\n",
    "from xautodl.procedures import (\n",
    "    prepare_seed,\n",
    "    prepare_logger,\n",
    "    save_checkpoint,\n",
    "    copy_checkpoint,\n",
    "    get_optim_scheduler,\n",
    ")\n",
    "from xautodl.utils import get_model_infos, obtain_accuracy\n",
    "from xautodl.log_utils import AverageMeter, time_string, convert_secs2time\n",
    "from xautodl.models import get_search_spaces\n",
    "\n",
    "# API\n",
    "from nats_bench import create\n",
    "\n",
    "# custom modules\n",
    "from custom.tss_model import TinyNetwork\n",
    "from xautodl.models.cell_searchs.genotypes import Structure\n",
    "from ZeroShotProxy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6018e93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "Namespace(data_path='./cifar.python', dataset='cifar10', search_space='tss', config_path='./configs/nas-benchmark/algos/weight-sharing.config', max_nodes=4, channel=16, num_cells=5, affine=0, track_running_stats=0, print_freq=200, gpu=0, workers=2, api_data_path='./api_data/NATS-tss-v1_0-3ffb9-simple/', save_dir='./results/tmp', zero_shot_score='synflow', rand_seed=123)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\"Training-free NAS on NATSBench (TSS)\")\n",
    "parser.add_argument(\"--data_path\", type=str, default='./cifar.python', help=\"The path to dataset\")\n",
    "parser.add_argument(\"--dataset\", type=str, default='cifar10',choices=[\"cifar10\", \"cifar100\", \"ImageNet16-120\"], help=\"Choose between Cifar10/100 and ImageNet-16.\")\n",
    "\n",
    "# channels and number-of-cells\n",
    "parser.add_argument(\"--search_space\", type=str, default='tss', help=\"The search space name.\")\n",
    "parser.add_argument(\"--config_path\", type=str, default='./configs/nas-benchmark/algos/weight-sharing.config', help=\"The path to the configuration.\")\n",
    "parser.add_argument(\"--max_nodes\", type=int, default=4, help=\"The maximum number of nodes.\")\n",
    "parser.add_argument(\"--channel\", type=int, default=16, help=\"The number of channels.\")\n",
    "parser.add_argument(\"--num_cells\", type=int, default=5, help=\"The number of cells in one stage.\")\n",
    "# parser.add_argument(\"--channel\", type=int, default=3, help=\"The number of channels.\")\n",
    "# parser.add_argument(\"--num_cells\", type=int, default=1, help=\"The number of cells in one stage.\")\n",
    "# parser.add_argument(\"--select_num\", type=int, default=100, help=\"The number of selected architectures to evaluate.\")\n",
    "parser.add_argument(\"--affine\", type=int, default=0, choices=[0, 1], help=\"Whether use affine=True or False in the BN layer.\")\n",
    "parser.add_argument(\"--track_running_stats\", type=int, default=0, choices=[0, 1], help=\"Whether use track_running_stats or not in the BN layer.\")\n",
    "\n",
    "# log\n",
    "parser.add_argument(\"--print_freq\", type=int, default=200, help=\"print frequency (default: 200)\")\n",
    "\n",
    "# custom\n",
    "parser.add_argument(\"--gpu\", type=int, default=0, help=\"\")\n",
    "parser.add_argument(\"--workers\", type=int, default=2, help=\"number of data loading workers\")\n",
    "parser.add_argument(\"--api_data_path\", type=str, default=\"./api_data/NATS-tss-v1_0-3ffb9-simple/\", help=\"\")\n",
    "parser.add_argument(\"--save_dir\", type=str, default='./results/tmp', help=\"Folder to save checkpoints and log.\")\n",
    "parser.add_argument('--zero_shot_score', type=str, default='synflow', choices=['etf','zico','zen','gradnorm','naswot','synflow','te_nas'])\n",
    "parser.add_argument(\"--rand_seed\", type=int, default=123, help=\"manual seed\")\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "if args.rand_seed is None or args.rand_seed < 0:\n",
    "    args.rand_seed = random.randint(1, 100000)\n",
    "\n",
    "print(args.rand_seed)\n",
    "print(args)\n",
    "xargs=args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8a05319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function with logger : Logger(dir=results/tmp, use-tf=False, writer=None)\n",
      "Arguments : -------------------------------\n",
      "data_path        : ./cifar.python\n",
      "dataset          : cifar10\n",
      "search_space     : tss\n",
      "config_path      : ./configs/nas-benchmark/algos/weight-sharing.config\n",
      "max_nodes        : 4\n",
      "channel          : 16\n",
      "num_cells        : 5\n",
      "affine           : 0\n",
      "track_running_stats : 0\n",
      "print_freq       : 200\n",
      "gpu              : 0\n",
      "workers          : 2\n",
      "api_data_path    : ./api_data/NATS-tss-v1_0-3ffb9-simple/\n",
      "save_dir         : ./results/tmp\n",
      "zero_shot_score  : synflow\n",
      "rand_seed        : 123\n",
      "Python  Version  : 3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]\n",
      "Pillow  Version  : 9.4.0\n",
      "PyTorch Version  : 2.0.1\n",
      "cuDNN   Version  : 8500\n",
      "CUDA available   : True\n",
      "CUDA GPU numbers : 2\n",
      "CUDA_VISIBLE_DEVICES : None\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available(), \"CUDA is not available.\"\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.set_num_threads(xargs.workers)\n",
    "prepare_seed(xargs.rand_seed)\n",
    "logger = prepare_logger(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78557cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create API = NATStopology(0/15625 architectures, fast_mode=True, file=) done\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "./configs/nas-benchmark/algos/weight-sharing.config\n",
      "Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=100, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, test_batch_size=512, class_num=10, xshape=(1, 3, 32, 32))\n",
      "||||||| cifar10    ||||||| Search-Loader-Num=391, Valid-Loader-Num=49, batch size=64\n",
      "||||||| cifar10    ||||||| Config=Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=100, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, test_batch_size=512, class_num=10, xshape=(1, 3, 32, 32))\n",
      "search space : ['none', 'skip_connect', 'nor_conv_1x1', 'nor_conv_3x3', 'avg_pool_3x3']\n"
     ]
    }
   ],
   "source": [
    "## API\n",
    "api = create(xargs.api_data_path, xargs.search_space, fast_mode=True, verbose=False)\n",
    "logger.log(\"Create API = {:} done\".format(api))\n",
    "\n",
    "## data\n",
    "train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n",
    "config = load_config(xargs.config_path, {\"class_num\": class_num, \"xshape\": xshape}, logger)\n",
    "search_loader, train_loader, valid_loader = get_nas_search_loaders(train_data,\n",
    "                                                                   valid_data,\n",
    "                                                                   xargs.dataset,\n",
    "                                                                   \"./configs/nas-benchmark/\",\n",
    "                                                                   (config.batch_size, config.test_batch_size),\n",
    "                                                                   xargs.workers,)\n",
    "logger.log(\"||||||| {:10s} ||||||| Search-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\".format(xargs.dataset, len(search_loader), len(valid_loader), config.batch_size))\n",
    "logger.log(\"||||||| {:10s} ||||||| Config={:}\".format(xargs.dataset, config))\n",
    "\n",
    "## model\n",
    "search_space = get_search_spaces(xargs.search_space, \"nats-bench\")\n",
    "logger.log(\"search space : {:}\".format(search_space))\n",
    "\n",
    "device = torch.device('cuda:{}'.format(xargs.gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c557c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_genotype(max_nodes, op_names):\n",
    "        genotypes = []\n",
    "        for i in range(1, max_nodes):\n",
    "            xlist = []\n",
    "            for j in range(i):\n",
    "                node_str = \"{:}<-{:}\".format(i, j)\n",
    "                op_name = random.choice(op_names)\n",
    "                xlist.append((op_name, j))\n",
    "            genotypes.append(tuple(xlist))\n",
    "        arch = Structure(genotypes)\n",
    "        return arch\n",
    "\n",
    "def search_find_best(xargs, xloader, n_samples = None, archs = None):\n",
    "    print(xargs.zero_shot_score.lower())\n",
    "    score_fn_name = \"compute_{}_score\".format(xargs.zero_shot_score.lower())\n",
    "    score_fn = globals().get(score_fn_name)\n",
    "    input_, target_ = next(iter(xloader))\n",
    "    resolution = input_.size(2)\n",
    "    batch_size = input_.size(0)\n",
    "    zero_shot_score_dict = None\n",
    "    arch_list = []\n",
    "    trainloader = search_loader if 'zico' in xargs.zero_shot_score.lower() else None\n",
    "    \n",
    "    if archs is None and n_samples is not None:\n",
    "        all_time = []\n",
    "        all_mem = []\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        for i in tqdm.tqdm(range(n_samples)):\n",
    "            # random sampling\n",
    "            arch = random_genotype(xargs.max_nodes, search_space)\n",
    "            network = TinyNetwork(xargs.channel, xargs.num_cells, arch, class_num)\n",
    "            network = network.to(device)\n",
    "            network.train()\n",
    "\n",
    "            start.record()\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "            info_dict = score_fn.compute_nas_score(network, gpu=xargs.gpu, trainloader=trainloader, resolution=resolution, batch_size=batch_size)\n",
    "\n",
    "            end.record()\n",
    "            torch.cuda.synchronize()\n",
    "            all_time.append(start.elapsed_time(end))\n",
    "#             all_mem.append(torch.cuda.max_memory_reserved())\n",
    "            all_mem.append(torch.cuda.max_memory_allocated())\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            arch_list.append(arch)\n",
    "            if zero_shot_score_dict is None: # initialize dict\n",
    "                zero_shot_score_dict = dict()\n",
    "                for k in info_dict.keys():\n",
    "                    zero_shot_score_dict[k] = []\n",
    "            for k, v in info_dict.items():\n",
    "                zero_shot_score_dict[k].append(v)\n",
    "\n",
    "        print(\"------Runtime------\")\n",
    "        print(\"All: {:.5f} ms\".format(np.mean(all_time)))\n",
    "        print(\"------Avg Mem------\")\n",
    "        print(\"All: {:.5f} GB\".format(np.mean(all_mem)/1e9))\n",
    "        print(\"------Max Mem------\")\n",
    "        print(\"All: {:.5f} GB\".format(np.max(all_mem)/1e9))\n",
    "        \n",
    "    elif archs is not None and n_samples is None:\n",
    "        all_time = []\n",
    "        all_mem = []\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        for arch in tqdm.tqdm(archs):\n",
    "            network = TinyNetwork(xargs.channel, xargs.num_cells, arch, class_num)\n",
    "            network = network.to(device)\n",
    "            network.train()\n",
    "\n",
    "            start.record()\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "            info_dict = score_fn.compute_nas_score(network, gpu=xargs.gpu, trainloader=trainloader, resolution=resolution, batch_size=batch_size)\n",
    "\n",
    "            end.record()\n",
    "            torch.cuda.synchronize()\n",
    "            all_time.append(start.elapsed_time(end))\n",
    "#             all_mem.append(torch.cuda.max_memory_reserved())\n",
    "            all_mem.append(torch.cuda.max_memory_allocated())\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            arch_list.append(arch)\n",
    "            if zero_shot_score_dict is None: # initialize dict\n",
    "                zero_shot_score_dict = dict()\n",
    "                for k in info_dict.keys():\n",
    "                    zero_shot_score_dict[k] = []\n",
    "            for k, v in info_dict.items():\n",
    "                zero_shot_score_dict[k].append(v)\n",
    "\n",
    "        print(\"------Runtime------\")\n",
    "        print(\"All: {:.5f} ms\".format(np.mean(all_time)))\n",
    "        print(\"------Avg Mem------\")\n",
    "        print(\"All: {:.5f} GB\".format(np.mean(all_mem)/1e9))\n",
    "        print(\"------Max Mem------\")\n",
    "        print(\"All: {:.5f} GB\".format(np.max(all_mem)/1e9))\n",
    "        \n",
    "    return arch_list, zero_shot_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562c71e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1042 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'asd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./tss_uniform_arch.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m     41\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump(uniform_archs, fp)\n\u001b[0;32m---> 42\u001b[0m archs, results \u001b[38;5;241m=\u001b[39m \u001b[43msearch_find_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muniform_archs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 76\u001b[0m, in \u001b[0;36msearch_find_best\u001b[0;34m(xargs, xloader, n_samples, archs)\u001b[0m\n\u001b[1;32m     73\u001b[0m start\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[1;32m     74\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mreset_peak_memory_stats()\n\u001b[0;32m---> 76\u001b[0m info_dict \u001b[38;5;241m=\u001b[39m \u001b[43mscore_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_nas_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m end\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[1;32m     79\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize()\n",
      "File \u001b[0;32m/home/junghyup/nas/nasbench201-random/random_my/NATSBench/ZeroShotProxy/compute_synflow_score.py:128\u001b[0m, in \u001b[0;36mcompute_nas_score\u001b[0;34m(model, gpu, trainloader, resolution, batch_size)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mcuda(gpu)\n\u001b[0;32m--> 128\u001b[0m grads_abs_list \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_synflow_per_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad_abs \u001b[38;5;129;01min\u001b[39;00m grads_abs_list:\n",
      "File \u001b[0;32m/home/junghyup/nas/nasbench201-random/random_my/NATSBench/ZeroShotProxy/compute_synflow_score.py:96\u001b[0m, in \u001b[0;36mcompute_synflow_per_weight\u001b[0;34m(net, inputs, mode)\u001b[0m\n\u001b[1;32m     94\u001b[0m _, output \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mforward(inputs)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m---> 96\u001b[0m \u001b[43masd\u001b[49m\n\u001b[1;32m     97\u001b[0m torch\u001b[38;5;241m.\u001b[39msum(output)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# select the gradients that we want to use for search/prune\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asd' is not defined"
     ]
    }
   ],
   "source": [
    "# ######### search across random N archs #########\n",
    "# archs, results = search_find_best(xargs, train_loader, n_samples=100)\n",
    "\n",
    "######### search across N archs uniformly sampled according to test acc. #########\n",
    "def uniform_sample_archs(search_space, xargs, api, n_samples=1000, dataset='cifar10'):\n",
    "    arch = random_genotype(xargs.max_nodes, search_space)\n",
    "    search_space = get_search_spaces(xargs.search_space, \"nats-bench\")\n",
    "    archs = arch.gen_all(search_space, xargs.max_nodes, False)\n",
    "    \n",
    "    def get_results_from_api(api, arch, dataset='cifar10'):\n",
    "        dataset_candidates = ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120']\n",
    "        assert dataset in dataset_candidates\n",
    "        index = api.query_index_by_arch(arch)\n",
    "        api._prepare_info(index)\n",
    "        archresult = api.arch2infos_dict[index]['200']\n",
    "        if dataset == 'cifar10-valid':\n",
    "            acc = archresult.get_metrics(dataset, 'x-valid', iepoch=199, is_random=False)['accuracy']\n",
    "        else:\n",
    "            acc = archresult.get_metrics(dataset, 'ori-test', iepoch=199, is_random=False)['accuracy']\n",
    "        return acc\n",
    "\n",
    "    accs = []\n",
    "    for a in archs:\n",
    "        accs.append(get_results_from_api(api, a, dataset))\n",
    "    interval = len(archs) // n_samples\n",
    "    sorted_indices = np.argsort(accs)\n",
    "    new_archs = []\n",
    "    for i, idx in enumerate(sorted_indices):\n",
    "        if i % interval == 0:\n",
    "            new_archs.append(archs[idx])\n",
    "    archs = new_archs\n",
    "    \n",
    "    return archs\n",
    "\n",
    "if os.path.exists(\"./tss_uniform_arch.pickle\"):\n",
    "    with open(\"./tss_uniform_arch.pickle\", \"rb\") as fp:\n",
    "        uniform_archs = pickle.load(fp)\n",
    "else:\n",
    "    uniform_archs = uniform_sample_archs(search_space, xargs, api, 1000, 'cifar10')\n",
    "    with open(\"./tss_uniform_arch.pickle\", \"wb\") as fp:\n",
    "        pickle.dump(uniform_archs, fp)\n",
    "archs, results = search_find_best(xargs, train_loader, archs=uniform_archs)\n",
    "\n",
    "\n",
    "# ######### search across all archs #########\n",
    "# def generate_all_archs(search_space, xargs):\n",
    "#     arch = random_genotype(xargs.max_nodes, search_space)\n",
    "#     archs = arch.gen_all(search_space, xargs.max_nodes, False)\n",
    "#     return archs\n",
    "\n",
    "# all_archs = generate_all_archs(search_space, xargs)\n",
    "# archs, results = search_find_best(xargs, train_loader, archs=all_archs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4147a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_api(api, arch, dataset='cifar10'):\n",
    "    dataset_candidates = ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120']\n",
    "    assert dataset in dataset_candidates\n",
    "    index = api.query_index_by_arch(arch)\n",
    "    api._prepare_info(index)\n",
    "    archresult = api.arch2infos_dict[index]['200']\n",
    "    \n",
    "    if dataset == 'cifar10-valid':\n",
    "        acc = archresult.get_metrics(dataset, 'x-valid', iepoch=199, is_random=False)['accuracy']\n",
    "    else:\n",
    "        acc = archresult.get_metrics(dataset, 'ori-test', iepoch=199, is_random=False)['accuracy']\n",
    "    flops = archresult.get_compute_costs(dataset)['flops']\n",
    "    params = archresult.get_compute_costs(dataset)['params']\n",
    "    \n",
    "    return acc, flops, params\n",
    "\n",
    "api_valid_accs, api_flops, api_params = [], [], []\n",
    "for a in archs:\n",
    "#     valid_acc, flops, params = get_results_from_api(api, a, 'cifar10')\n",
    "    valid_acc, flops, params = get_results_from_api(api, a, 'cifar100')\n",
    "#     valid_acc, flops, params = get_results_from_api(api, a, 'ImageNet16-120')\n",
    "    api_valid_accs.append(valid_acc)\n",
    "    api_flops.append(flops)\n",
    "    api_params.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e525a88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_scale = 1.1\n",
    "\n",
    "# rank_agg = None\n",
    "# l = len(api_flops)\n",
    "# rank_agg = np.log(stats.rankdata(api_flops) / l)\n",
    "# for k in results.keys():\n",
    "#     if rank_agg is None:\n",
    "#         rank_agg = np.log( stats.rankdata(results[k]) / l)\n",
    "#     else:\n",
    "#         rank_agg = rank_agg + np.log( stats.rankdata(results[k]) / l)\n",
    "    \n",
    "\n",
    "# best_idx = np.argmax(rank_agg)\n",
    "\n",
    "# best_arch, acc = archs[best_idx], api_valid_accs[best_idx]\n",
    "# if api is not None:\n",
    "#     print(\"{:}\".format(api.query_by_arch(best_arch, \"200\")))\n",
    "    \n",
    "\n",
    "# x = stats.rankdata(rank_agg)\n",
    "# y = stats.rankdata(api_valid_accs)\n",
    "# kendalltau = stats.kendalltau(x, y)\n",
    "# spearmanr = stats.spearmanr(x, y)\n",
    "# pearsonr = stats.pearsonr(x, y)\n",
    "# print(\"aggregated: {}\\t{}\\t{}\\t\".format(kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "# plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "# plt.scatter(x, y, linewidths=0.1)\n",
    "# plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "# plt.title(\"Rank_agg\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# for each\n",
    "# metrics = {'FLOPs':api_flops, 'Params':api_params}\n",
    "metrics = {}\n",
    "for k, v in results.items():\n",
    "    metrics[k] = v\n",
    "    \n",
    "    print(k)\n",
    "    best_idx = np.argmax(v)\n",
    "\n",
    "    best_arch, acc = archs[best_idx], api_valid_accs[best_idx]\n",
    "    if api is not None:\n",
    "        print(\"{:}\".format(api.query_by_arch(best_arch, \"200\")))\n",
    "        \n",
    "        \n",
    "for k in metrics.keys():\n",
    "    x = stats.rankdata(metrics[k])\n",
    "    y = stats.rankdata(api_valid_accs)\n",
    "    kendalltau = stats.kendalltau(x, y)\n",
    "    spearmanr = stats.spearmanr(x, y)\n",
    "    pearsonr = stats.pearsonr(x, y)\n",
    "    print(\"{}: {}\\t{}\\t{}\\t\".format(k, kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "    plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "    plt.scatter(x, y, linewidths=0.1)\n",
    "    plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "    plt.title(\"Rank_{}\".format(k))\n",
    "    plt.show()\n",
    "    \n",
    "# for each\n",
    "for k, v in results.items():\n",
    "    metrics[k] = v\n",
    "for k in results.keys():\n",
    "    x = stats.rankdata(metrics[k])\n",
    "    y = stats.rankdata(api_params)\n",
    "    kendalltau = stats.kendalltau(x, y)\n",
    "    spearmanr = stats.spearmanr(x, y)\n",
    "    pearsonr = stats.pearsonr(x, y)\n",
    "    print(\"{}: {}\\t{}\\t{}\\t\".format(k, kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "    plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "    plt.scatter(x, y, linewidths=0.1)\n",
    "    plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "    plt.title(\"{} vs. Params\".format(k))\n",
    "    plt.show()\n",
    "    \n",
    "# for each\n",
    "for k, v in results.items():\n",
    "    metrics[k] = v\n",
    "for k in results.keys():\n",
    "    x = stats.rankdata(metrics[k])\n",
    "    y = stats.rankdata(api_flops)\n",
    "    kendalltau = stats.kendalltau(x, y)\n",
    "    spearmanr = stats.spearmanr(x, y)\n",
    "    pearsonr = stats.pearsonr(x, y)\n",
    "    print(\"{}: {}\\t{}\\t{}\\t\".format(k, kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "    plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "    plt.scatter(x, y, linewidths=0.1)\n",
    "    plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "    plt.title(\"{} vs. FLOPs\".format(k))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
